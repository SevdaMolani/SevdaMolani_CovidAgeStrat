{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "433323c9-c631-49d7-8737-2fc18da4662c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "_Author_ = \"Sevda Molani\"\n",
    "\n",
    "_copyright_ = \"2022 Sevda Molani\"\n",
    "\n",
    "_License_ = \"Institute for Systems Biology\"\n",
    "\n",
    "_Version_ = \"1.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2df3c4a9-b19e-427e-873e-239f7dbb92ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.installPyPI('graphviz')\n",
    "# dbutils.library.installPyPI('pandas')\n",
    "dbutils.library.installPyPI('scikit-learn', version=\"0.24.0\")\n",
    "dbutils.library.installPyPI('xgboost')\n",
    "dbutils.library.installPyPI('imblearn')\n",
    "dbutils.library.installPyPI('imbalanced-learn')\n",
    "dbutils.library.installPyPI('shap',version=\"0.35.0\")\n",
    "dbutils.library.installPyPI('eli5')\n",
    "dbutils.library.installPyPI('plotly')\n",
    "dbutils.library.installPyPI('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba567472-db76-4cb8-9cdd-05c73adc3604",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, train_test_split, cross_val_score, LeaveOneOut\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, MultiTaskLassoCV, MultiTaskLasso, Lasso, LassoCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from catboost import CatBoostClassifier,Pool\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from sklearn.metrics import auc as AUC\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from scipy import stats, interp\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_ind_from_stats\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import t\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import graphviz\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caed3fda-d925-4973-9306-01a558c1477b",
     "showTitle": true,
     "title": "1. Loading data"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "\"\"\"\n",
    "SELECT \n",
    "sm_positive_delta_results_feb.pat_id, \n",
    "sm_positive_delta_results_feb.pat_enc_csn_id,\n",
    "sm_positive_delta_results_feb.instance, \n",
    "sm_positive_delta_results_feb.admissiondatetime,\n",
    "sm_positive_delta_results_feb.onehourbase,\n",
    "sm_positive_delta_results_feb.ETHNICGROUP, \n",
    "sm_positive_delta_results_feb.sex, \n",
    "sm_positive_delta_results_feb.race,\n",
    "sm_positive_delta_results_feb.age, \n",
    "sm_patt_delta_baseline_feb.first_who, \n",
    "sm_patt_delta_baseline_feb.first_who_date, \n",
    "sm_patt_delta_baseline_feb.max_who_28,\n",
    "sm_patt_delta_baseline_feb.max_who_1,\n",
    "sm_patt_delta_baseline_feb.max_who_7,\n",
    "sm_patt_delta_baseline_feb.max_who_14,\n",
    "sm_patt_delta_baseline_feb.max_who_56,\n",
    "sm_patt_delta_vasso_Immuno_feb.Vasso_use,\n",
    "sm_patt_delta_vasso_Immuno_feb.Administered_dose_count,\n",
    "sm_patt_delta_vasso_Immuno_feb.Vaccination_status,\n",
    "CCI,htn, asthma, COPD, cancer, liver_disease, ckd, hld, osa, diabetes, sot, Coronary_arteriosclerosis,Heart_failure,Cardiomyopathy, ics, dementia,\n",
    "height, weight, BMI,\n",
    "HR_max, HR_mean, HR_min,HR_std, SBP_max, SBP_mean, SBP_min,SBP_std, DBP_max, DBP_mean, DBP_min,DBP_std, temp_max, temp_mean, temp_min,temp_std, RR_max, RR_mean, RR_min,RR_std, spo2_max, spo2_mean, spo2_min,spo2_std,Last_spo2,Last_RR,Last_temp,Last_SBP,Last_DBP,Last_HR,\n",
    "\n",
    "resultvalue_HCO3,resultvalue_CI,resultvalue_BUN,resultvalue_PLT,resultvalue_eosabs,resultvalue_neuabs,resultvalue_ast,resultvalue_alt,resultvalue_creatinine,resultvalue_potassium,resultvalue_alb,resultvalue_sodium,resultvalue_HGB,resultvalue_HCT,resultvalue_lymph,resultvalue_WBC,resultvalue_calcium,resultvalue_RBC,resultvalue_Baso,resultvalue_Mono,resultvalue_Alkaline,resultvalue_Anion,resultvalue_Bilirubin,resultvalue_Globulin,resultvalue_Protein,resultvalue_Glucose,resultvalue_ddimer,resultvalue_be,resultvalue_ldh,resultvalue_pct,resultvalue_mg,resultvalue_inr,resultvalue_fr,resultvalue_buncreat,resultvalue_Proth,resultvalue_egfr,resultvalue_crp,Last_Glucose,Last_Protein,Last_Globulin,Last_Bilirubin,Last_Anion,Last_Alkaline,Last_Mono,Last_Baso,Last_RBC,Last_HCO3,Last_CI,Last_BUN,Last_PLT,Last_eosabs,Last_neuabs,Last_ast,Last_alt,Last_calcium,Last_creatinine,Last_potassium,Last_alb,Last_sodium,Last_HGB,Last_HCT,Last_lymph,Last_wbc,Last_ddimer,Last_be,Last_ldh,Last_pct,Last_mg,Last_inr,Last_fr,Last_buncreat,Last_Proth,Last_egfr,Last_crp\n",
    "\n",
    "FROM rdp_phi_sandbox.sm_positive_delta_results_feb\n",
    "  INNER JOIN rdp_phi_sandbox.sm_patt_delta_baseline_feb ON (sm_patt_delta_baseline_feb.pat_id = sm_positive_delta_results_feb.pat_id\n",
    "    AND sm_patt_delta_baseline_feb.pat_enc_csn_id = sm_positive_delta_results_feb.pat_enc_csn_id AND sm_patt_delta_baseline_feb.instance = sm_positive_delta_results_feb.instance)\n",
    "  INNER JOIN rdp_phi_sandbox.sm_patt_delta_labs_feb ON (sm_positive_delta_results_feb.pat_id = sm_patt_delta_labs_feb.pat_id\n",
    "    AND sm_positive_delta_results_feb.pat_enc_csn_id = sm_patt_delta_labs_feb.pat_enc_csn_id AND sm_positive_delta_results_feb.instance = sm_patt_delta_labs_feb.instance)\n",
    "  INNER JOIN rdp_phi_sandbox.sm_patt_delta_vasso_Immuno_feb ON (sm_positive_delta_results_feb.pat_id = sm_patt_delta_vasso_Immuno_feb.pat_id\n",
    "    AND sm_positive_delta_results_feb.pat_enc_csn_id = sm_patt_delta_vasso_Immuno_feb.pat_enc_csn_id AND sm_positive_delta_results_feb.instance = sm_patt_delta_vasso_Immuno_feb.instance)\n",
    "  INNER JOIN rdp_phi.patientrace ON (sm_positive_delta_results_feb.pat_id = patientrace.pat_id AND sm_positive_delta_results_feb.instance = patientrace.instance)\n",
    "  LEFT JOIN rdp_phi_sandbox.sm_patt_delta_vital_feb ON (sm_positive_delta_results_feb.pat_id = sm_patt_delta_vital_feb.pat_id\n",
    "    AND sm_positive_delta_results_feb.pat_enc_csn_id = sm_patt_delta_vital_feb.pat_enc_csn_id AND sm_positive_delta_results_feb.instance = sm_patt_delta_vital_feb.instance)\n",
    "  \n",
    "group by \n",
    "sm_positive_delta_results_feb.pat_id, \n",
    "sm_positive_delta_results_feb.pat_enc_csn_id,\n",
    "sm_positive_delta_results_feb.instance, \n",
    "sm_positive_delta_results_feb.admissiondatetime,\n",
    "sm_positive_delta_results_feb.onehourbase,\n",
    "sm_positive_delta_results_feb.ETHNICGROUP, \n",
    "sm_positive_delta_results_feb.sex, \n",
    "sm_positive_delta_results_feb.race,\n",
    "sm_positive_delta_results_feb.age, \n",
    "sm_patt_delta_baseline_feb.first_who, \n",
    "sm_patt_delta_baseline_feb.first_who_date, \n",
    "sm_patt_delta_baseline_feb.max_who_28,\n",
    "sm_patt_delta_baseline_feb.max_who_1,\n",
    "sm_patt_delta_baseline_feb.max_who_7,\n",
    "sm_patt_delta_baseline_feb.max_who_14,\n",
    "sm_patt_delta_baseline_feb.max_who_56,\n",
    "sm_patt_delta_vasso_Immuno_feb.Vasso_use,\n",
    "sm_patt_delta_vasso_Immuno_feb.Administered_dose_count,\n",
    "sm_patt_delta_vasso_Immuno_feb.Vaccination_status,\n",
    "CCI,htn, asthma, COPD, cancer, liver_disease, ckd, hld, osa, diabetes, sot, Coronary_arteriosclerosis,Heart_failure,Cardiomyopathy, ics, dementia,\n",
    "height, weight, BMI,\n",
    "HR_max, HR_mean, HR_min,HR_std, SBP_max, SBP_mean, SBP_min,SBP_std, DBP_max, DBP_mean, DBP_min,DBP_std, temp_max, temp_mean, temp_min,temp_std, RR_max, RR_mean, RR_min,RR_std, spo2_max, spo2_mean, spo2_min,spo2_std,Last_spo2,Last_RR,Last_temp,Last_SBP,Last_DBP,Last_HR,\n",
    "resultvalue_HCO3,resultvalue_CI,resultvalue_BUN,resultvalue_PLT,resultvalue_eosabs,resultvalue_neuabs,resultvalue_ast,resultvalue_alt,resultvalue_creatinine,resultvalue_potassium,resultvalue_alb,resultvalue_sodium,resultvalue_HGB,resultvalue_HCT,resultvalue_lymph,resultvalue_WBC,resultvalue_calcium,resultvalue_RBC,resultvalue_Baso,resultvalue_Mono,resultvalue_Alkaline,resultvalue_Anion,resultvalue_Bilirubin,resultvalue_Globulin,resultvalue_Protein,resultvalue_Glucose,resultvalue_ddimer,resultvalue_be,resultvalue_ldh,resultvalue_pct,resultvalue_mg,resultvalue_inr,resultvalue_fr,resultvalue_buncreat,resultvalue_Proth,resultvalue_egfr,resultvalue_crp,Last_Glucose,Last_Protein,Last_Globulin,Last_Bilirubin,Last_Anion,Last_Alkaline,Last_Mono,Last_Baso,Last_RBC,Last_HCO3,Last_CI,Last_BUN,Last_PLT,Last_eosabs,Last_neuabs,Last_ast,Last_alt,Last_calcium,Last_creatinine,Last_potassium,Last_alb,Last_sodium,Last_HGB,Last_HCT,Last_lymph,Last_wbc,Last_ddimer,Last_be,Last_ldh,Last_pct,Last_mg,Last_inr,Last_fr,Last_buncreat,Last_Proth,Last_egfr,Last_crp\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "df = df.dropDuplicates([\"pat_id\",\"pat_enc_csn_id\",\"instance\",\"admissiondatetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a73c3f7c-82a5-47e5-8f3b-6f713d3a57d7",
     "showTitle": true,
     "title": "2. Preprocessing"
    }
   },
   "outputs": [],
   "source": [
    "df = df.filter((df.BMI<=65) & (df.BMI>=9))\n",
    "\n",
    "df = df.filter(~((df.first_who.isNull()) | (df.max_who_1.isNull()) | (df.max_who_7.isNull()) | (df.max_who_14.isNull()) | (df.max_who_28.isNull()) | (df.max_who_56.isNull())))\n",
    "\n",
    "\n",
    "df = df.withColumn(\"first_who\", when(df[\"first_who\"] == 8, 7).otherwise(df[\"first_who\"]))\n",
    "\n",
    "###Max Who filters\n",
    "df = df.filter((df.max_who_1 != 2) & (df.max_who_7 != 2) & (df.max_who_14 != 2) & (df.max_who_28 != 2) & (df.max_who_56 != 2))\n",
    "\n",
    "###First Who filters\n",
    "#df = df.filter((df.first_who != 2))\n",
    "df = df.filter((df.first_who != 2) & (df.first_who != 6) & (df.first_who != 7))\n",
    "\n",
    "#keep only the first record\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col\n",
    "window = Window.partitionBy(df['pat_id']).orderBy(df['admissiondatetime'])\n",
    "\n",
    "df = df.select('*', rank().over(window).alias('rank')).filter(col('rank') <= 1) \n",
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7cdfc453-3ffb-4631-8ee3-18040c4fdc10",
     "showTitle": true,
     "title": "Age groups"
    }
   },
   "outputs": [],
   "source": [
    "#df = df.filter((df.age >= 18) & (df.age <= 110))\n",
    "\n",
    "df28Old = df.filter(df.age >= 50) #Age filter\n",
    "\n",
    "df28Young = df.filter(df.age < 50) #Age filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70d885b2-08be-4686-9e13-9e554ca42354",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdfAll = df.toPandas() #All Patients\n",
    "pdf = pdfAll "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e547ba9-3965-4790-89d3-f0e8ad7db488",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cols = ['Last_Glucose','Last_Protein','Last_Globulin','Last_Bilirubin','Last_Anion','Last_Alkaline','Last_Mono','Last_Baso','Last_RBC','Last_HCO3','Last_CI','Last_BUN','Last_PLT','Last_eosabs','Last_neuabs','Last_ast','Last_alt',\n",
    "'Last_calcium','Last_creatinine','Last_potassium','Last_alb','Last_sodium','Last_HGB','Last_HCT','Last_lymph','Last_wbc']\n",
    "\n",
    "pdf[cols] = pdf[cols].apply(pd.to_numeric, downcast='float', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9dc655e-2723-4599-9d3e-cd6546f81b66",
     "showTitle": true,
     "title": "Missing Values"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.mode.use_inf_as_na = True\n",
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "SD = ['HR_std','SBP_std','DBP_std','RR_std','temp_std','spo2_std','Administered_dose_count','ETHNICGROUP']\n",
    "for c in SD:\n",
    "    pdf[c] = pdf[c].fillna(0)\n",
    "\n",
    "print(\" \\nCount total NaN at each column in a DataFrame : \\n\\n\",((pdf.isnull().sum())/len(pdf))*100)\n",
    "  \n",
    "pdf = pdf.loc[:, (((pdf.isnull().sum())/len(pdf))*100) <= 20]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b6d1588-8f32-4fe8-b086-a285a40600cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "numerical = ['BMI','age',\n",
    "             'HR_mean', 'HR_std', 'SBP_mean', 'SBP_std','DBP_mean','DBP_std', 'temp_mean', 'temp_std', 'RR_mean', 'RR_std',  'spo2_mean', 'spo2_std',\n",
    "              'resultvalue_HCO3', 'resultvalue_CI', 'resultvalue_BUN', 'resultvalue_PLT', 'resultvalue_neuabs', 'resultvalue_ast', 'resultvalue_alt', 'resultvalue_creatinine', 'resultvalue_potassium', 'resultvalue_alb', 'resultvalue_sodium', 'resultvalue_HGB', 'resultvalue_HCT', 'resultvalue_lymph', 'resultvalue_WBC', 'resultvalue_calcium', 'resultvalue_RBC', 'resultvalue_Mono', 'resultvalue_Alkaline', 'resultvalue_Anion', 'resultvalue_Bilirubin', 'resultvalue_Protein', 'resultvalue_Glucose']\n",
    "\n",
    "categorical = ['CCI','ETHNICGROUP', 'race','sex','Vasso_use']#, 'htn', 'asthma', 'COPD', 'cancer', 'liver_disease', 'ckd', 'hld', 'osa', 'diabetes', 'sot', 'Coronary_arteriosclerosis', 'Heart_failure', 'Cardiomyopathy', 'ics', 'dementia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd3b6e77-59cd-4497-bc7e-3c1022ff996c",
     "showTitle": true,
     "title": "Encodeing boolean/categorical columns"
    }
   },
   "outputs": [],
   "source": [
    "# Converting categorical data to its numerical codes\n",
    "class LabelEncoder(): \n",
    "    # Encoder function\n",
    "    def fit(self, labels, max_class=float('inf')):\n",
    "        \"\"\"\n",
    "        The function to create the encoder mapping. \n",
    "\n",
    "        Parameters:\n",
    "            labels: The original set of categorical labels\n",
    "            max_class: The maximum number of categories defaulted as infinite, so that all unique categories are kept \n",
    "\n",
    "        Returns: \n",
    "            None\n",
    "        \"\"\"\n",
    "        self.encoder = {}\n",
    "        self.i = 0 \n",
    "        for label in labels:\n",
    "            self.encoder[label] = self.i\n",
    "            if self.i < max_class - 1:\n",
    "                self.i += 1\n",
    "            \n",
    "    def transform(self, labels):\n",
    "        \"\"\"\n",
    "        The function to transfer original categorical labels to numerical codes using the encoder mapping. \n",
    "\n",
    "        Parameters:\n",
    "            labels: The original categorical labels \n",
    "\n",
    "        Returns: \n",
    "            res: Transferred numerical labels as a numpy array\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        \n",
    "        for label in labels:\n",
    "            res.append(self.encoder[label])\n",
    "        return np.array(res)\n",
    "      \n",
    "le = LabelEncoder() # Create a instance of LabelEncoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0fd5941-21f7-4e8e-bccf-9512b3de9a70",
     "showTitle": true,
     "title": "Creating severity label based on who_grade"
    }
   },
   "outputs": [],
   "source": [
    "###Creating severity label based on who_grade###\n",
    "\n",
    "def who2sev(labels):\n",
    "    res = []\n",
    "    encoder = {3:0, 4:0, 5:0, 6:0, 7:0, 8:1}\n",
    "    for label in labels:\n",
    "        res.append(encoder[label])\n",
    "    return np.array(res)\n",
    "  \n",
    "pdf['bi_severity_1'] = who2sev(pdf['max_who_1'])\n",
    "pdf['bi_severity_7'] = who2sev(pdf['max_who_7'])\n",
    "pdf['bi_severity_14'] = who2sev(pdf['max_who_14'])\n",
    "pdf['bi_severity_28'] = who2sev(pdf['max_who_28'])\n",
    "pdf['bi_severity_56'] = who2sev(pdf['max_who_56'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06adfd7c-e751-40f4-9419-42c25f3fb96c",
     "showTitle": true,
     "title": "Categorical to Numberical"
    }
   },
   "outputs": [],
   "source": [
    "for compl in ['Vasso_use',\n",
    "   'htn', 'asthma', 'COPD', 'cancer', 'liver_disease', 'ckd', 'hld', 'osa', 'diabetes', 'sot', 'Coronary_arteriosclerosis', 'Heart_failure', 'Cardiomyopathy', 'ics', 'dementia']:\n",
    "    le.fit(['no', 'yes'])\n",
    "    pdf[compl] = le.transform(pdf[compl])\n",
    "    \n",
    "    \n",
    "#for compl in ['Vasso_use']:\n",
    " # le.fit(['no', 'yes'])\n",
    " # pdf[compl] = le.transform(pdf[compl])\n",
    "    \n",
    "pdf = pdf.replace({'sex': {'Female': 0, 'Male': 1,'Unknown': 0,'Other': 0}})   \n",
    "  \n",
    "  \n",
    "pdf = pdf.replace({'ETHNICGROUP': {'Not Hispanic or Latino': 0,'Filipino':0, 'Hispanic or Latino': 1, \\\n",
    "                              'American': 0, \\\n",
    "                              'Samoan': 0, \\\n",
    "                               'Unknown': 0, 'Patient Refused': 0,\n",
    "                                  'Hmong':0,'Thai':0, '0': 0, 'Cambodian':0}})\n",
    "\n",
    "pdf = pdf.replace({'race': {'White or Caucasian': 0, 'American Indian or Alaska Native': 1, \\\n",
    "                              'Unknown': 1, \\\n",
    "                              'Native Hawaiian or Other Pacific Islander': 1, \\\n",
    "                               'Black or African American': 1, 'Asian': 1,'Other':1,'Patient Refused':1}})\n",
    "\n",
    "\n",
    "\n",
    "comorbidities = [ 'htn', 'asthma', 'COPD', 'cancer', 'liver_disease', 'ckd', 'hld', 'osa', 'diabetes', 'sot', 'Coronary_arteriosclerosis', 'Heart_failure', 'Cardiomyopathy', 'ics', 'dementia']\n",
    "\n",
    "pdf['Total'] = pdf[comorbidities].sum(axis=1)\n",
    "\n",
    "pdf = pdf.replace({'Vaccination_status': {'NotVaccinated': 0, 'Half': 1,'Fully': 2,'Booster': 3}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f19050b-ae3f-48a6-b154-e01d6d4a1491",
     "showTitle": true,
     "title": "Outliers"
    }
   },
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#sns.boxplot(pdf[\"EOSABS\"])\n",
    "\n",
    "# Outlier detection\n",
    "def get_mad_based_z_score(column_name):\n",
    "    mad = column_name.mad(skipna=True)\n",
    "    median = column_name.median()\n",
    "    z_score = (0.6725*(column_name - median)/mad).abs()\n",
    "    return z_score\n",
    "\n",
    "# Numerical data\n",
    "cols = numerical\n",
    "\n",
    "threshold = 3.5\n",
    "for c in cols:\n",
    "    z = get_mad_based_z_score(pdf[c])\n",
    "    pdf.loc[z > threshold, c] = pdf[c].median()\n",
    "    pdf[c] = pdf[c].fillna(pdf[c].median())     # fill NA\n",
    "\n",
    "pdf.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40a0c917-26f1-4d24-9928-99286b6ebb9e",
     "showTitle": true,
     "title": "3. Statistical analysis: Chi-squared Test of Independence"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "def chi_squre_test(table, los):\n",
    "    \"\"\"\n",
    "    The function to perform Chi-squared Test of Independence. \n",
    "\n",
    "\n",
    "    Parameters:\n",
    "        table: The Contingency Table. \n",
    "\n",
    "    Returns: \n",
    "        p: The calculated p-value. \n",
    "    \"\"\"\n",
    "    stat, p, dof, expected = chi2_contingency(table)\n",
    "    print('Degree of freedom is %d' % dof)\n",
    "    print(expected)\n",
    "    \n",
    "    # interpret test-statistic\n",
    "    prob = 1 - los\n",
    "    critical = chi2.ppf(prob, dof)\n",
    "    print('probability = %.3f, critical = %.3f, stat = %.3f' % (prob, critical, stat))\n",
    "    if np.abs(stat) >= critical:\n",
    "        print('Dependent (reject H0)')\n",
    "    else:\n",
    "        print('Independent (fail to reject H0)')\n",
    "    \n",
    "    # interpret p-value\n",
    "    alpha = 1.0 - prob\n",
    "    print('Level of significance is %.2f' % alpha)\n",
    "    print('p-value = %.2e' % p)\n",
    "    if p <= alpha:\n",
    "        print('Dependent (reject H0)')\n",
    "    else:\n",
    "        print('Independent (fail to reject H0)')\n",
    "        \n",
    "    return p\n",
    "  \n",
    "  \n",
    "###################################################################################################  \n",
    "  \n",
    "  \n",
    "significant_Cat_features = [] # create a list to save all statistically significant risk factors\n",
    "for condition in categorical:\n",
    "   \n",
    "    print(\"Contingency Table showing correlation between severity and %s.\" % condition)\n",
    "    data_crosstab = pd.crosstab(pdf[condition],  \n",
    "                                pdf['bi_severity_7'], \n",
    "                                margins = False)\n",
    "    oddsr, p = fisher_exact(data_crosstab, alternative='two-sided')\n",
    "    chi2_stat, p_val, dof, ex = stats.chi2_contingency(data_crosstab)\n",
    "    print(\"Chi square-Pvalue, %.03f\" %p_val)\n",
    "    print(\"Fisher-Pvalue, %.03f\" %p)\n",
    "    print(\"ODDS, %.03f\" %oddsr)\n",
    "    print(data_crosstab)\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"----Chi-squared Test of Independence for %s----\" % condition)\n",
    "    print()\n",
    "\n",
    "    if chi_squre_test(data_crosstab, 0.1) <= 0.1:\n",
    "        print(\"----The condition %s is highly correlated to severity of covid19----\" % condition)\n",
    "        significant_Cat_features.append(condition)\n",
    "    else:\n",
    "      print(\"----The condition %s is not!!!----\" % condition)\n",
    "      \n",
    "\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8fc6623-ae1d-49d9-8017-a63641f1dd36",
     "showTitle": true,
     "title": "Unpaired t_test for two outcome (Numerical)"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "significant_Num_features = []\n",
    "for condition in numerical: \n",
    "    \n",
    "  data = pdf[condition]\n",
    "  data1 = pdf[pdf['bi_severity_7'] == 0][condition]\n",
    "  data2 = pdf[pdf['bi_severity_7'] == 1][condition]\n",
    "  \n",
    "  #stat, p = shapiro(data)\n",
    "  #if p > 0.05:\n",
    "   # print('Probably Gaussian')\n",
    "    #stat_, p_ = stats.f_oneway(data1, data2, data3)\n",
    "  #else:\n",
    "  #  print('Probably not Gaussian')\n",
    "  # stat_, p_ = kruskal(data1, data2, data3)\n",
    "  \n",
    "  stat_, p_ = stats.ttest_ind(data1, data2)\n",
    "  #stat_, p_ = stats.f_oneway(data1, data2)\n",
    "\n",
    "  # interpret p-value\n",
    "  alpha = 0.05\n",
    "  print('Level of significance is %.2f' % alpha)\n",
    "  print('p-value = %.2e' % p_)\n",
    "  if p_ <= alpha:\n",
    "    print('Difference among the population means (reject H0)')\n",
    "  else:\n",
    "    print('Equal population means (fail to reject H0)')\n",
    "    \n",
    "  if p_ <= 0.05:\n",
    "    print(\"----The condition %s is highly correlated to Severity of Covid19----\" % condition)\n",
    "    significant_Num_features.append(condition)\n",
    "    #feature_ranking.append((p_, condition))\n",
    "  else:\n",
    "    print(\"----The condition %s is not!!!----\" % condition)\n",
    "  print()\n",
    "\n",
    "#feature_ranking.sort(key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84f445ec-dfc1-4d3c-a2d6-4b3e79f021c8",
     "showTitle": true,
     "title": "Mann Whitney U test"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "feature_ranking = []\n",
    "for condition in numerical: \n",
    "    \n",
    "  data = pdf[condition]\n",
    "  data1 = pdf[pdf['bi_severity_7'] == 0][condition]\n",
    "  data2 = pdf[pdf['bi_severity_7'] == 1][condition]\n",
    "  \n",
    "  stat_, p_ = stats.mannwhitneyu(data1, data2)\n",
    "\n",
    "  # interpret p-value\n",
    "  alpha = 0.1\n",
    "  print('Level of significance is %.2f' % alpha)\n",
    "  print('p-value = %.2e' % p_)\n",
    "  if p_ <= alpha:\n",
    "    print('Difference among the population means (reject H0)')\n",
    "  else:\n",
    "    print('Equal population means (fail to reject H0)')\n",
    "    \n",
    "  if p_ <= 0.1:\n",
    "    print(\"----The condition %s is highly correlated to Severity of Covid19----\" % condition)\n",
    "    feature_ranking.append((p_, condition))\n",
    "  else:\n",
    "    print(\"----The condition %s is not!!!----\" % condition)\n",
    "  print()\n",
    "\n",
    "feature_ranking.sort(key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6d23e3b-a3ab-402e-84a6-66cb63a9e537",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf.groupby(\"bi_severity_7\")[\"first_who\"].describe().T\n",
    "\n",
    "#pdf[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62b3a84f-3ce4-41a9-b754-0cea7239ea6e",
     "showTitle": true,
     "title": "4. Machine learning"
    }
   },
   "outputs": [],
   "source": [
    "features = numerical + categorical+['first_who','Total','Vaccination_status']\n",
    "\n",
    "print('Total number of features: %d' % len(features))\n",
    "\n",
    "data = pdf[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7c98ff4-8759-4502-9184-c7ec1764b11c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_performance(pred_res, target):\n",
    "\n",
    "    TP, FP, TN, FN = 0.01, 0.01, 0.01, 0.01\n",
    "    for pred_, target_ in zip(pred_res, target):\n",
    "        if pred_ == 1:\n",
    "            if target_ == pred_:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if target_ == pred_:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "                \n",
    "    Population = TN+FN+TP+FP\n",
    "    Prevalence = np.round((TP+FN)/Population, 4)\n",
    "    Accuracy   = np.round((TP+TN)/Population, 4)\n",
    "    Precision  = np.round(TP/(TP+FP), 4) # PPV\n",
    "    NPV        = np.round(TN/(TN+FN), 4)\n",
    "    FDR        = np.round(FP/(TP+FP), 4)\n",
    "    FOR        = np.round(FN/(TN+FN), 4) \n",
    "    check_Pos  = Precision + FDR\n",
    "    check_Neg  = NPV + FOR\n",
    "    Recall     = np.round(TP/(TP+FN), 4)\n",
    "    FPR        = np.round(FP/(TN+FP), 4)\n",
    "    FNR        = np.round(FN/(TP+FN), 4)\n",
    "    TNR        = np.round(TN/(TN+FP), 4) \n",
    "    check_Pos2 = Recall + FNR\n",
    "    check_Neg2 = FPR + TNR\n",
    "    LRPos      = np.round(Recall/FPR, 4) \n",
    "    LRNeg      = np.round(FNR/TNR , 4)\n",
    "    DOR        = np.round(LRPos/LRNeg)\n",
    "    F1         = np.round (2*((Precision*Recall)/(Precision+Recall)), 4)\n",
    "    MCC        = np.round (((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)), 4)\n",
    "    BM         = Recall+TNR-1\n",
    "    MK         = Precision+NPV-1\n",
    "    Specificity = np.round(TN/(TN+FP), 4)\n",
    "    Youden = (np.round(TN/(TN+FP), 4)+np.round(TP/(TP+FN), 4))-1\n",
    "                \n",
    "    return [TP, FP, TN, FN, Population ,Prevalence ,Accuracy ,Precision ,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,DOR,F1,MCC, BM,MK,Specificity,Youden]\n",
    "  \n",
    "performance_stats = ['TP', 'FP', 'TN', 'FN', 'Population' ,'Prevalence' ,'Accuracy' ,'Precision', 'NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LRPos','LRNeg','DOR','F1','MCC', 'BM','MK','Specificity','Youden']\n",
    "  \n",
    "def compute_auc(pred_prob, target, pos_label=None):\n",
    "    \"\"\"\n",
    "    The function to compute the classification performance based on the predicted results. \n",
    "\n",
    "    Parameters:\n",
    "        pred_prob: The predicted probabilities. \n",
    "        target: The true labels. \n",
    "    Returns: \n",
    "        The list of computed AUC score. \n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred_prob[:, 1], pos_label=pos_label)\n",
    "\n",
    "    return AUC(fpr, tpr)\n",
    "  \n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################Function to remove one of the correlated values\n",
    "\n",
    "def my_abs(num):\n",
    "    if math.copysign(1, num) < 0:\n",
    "        return -num\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "########################Removing the correlated features\n",
    "def correlation(dataset, threshold):\n",
    "  col_corr = set() \n",
    "  #corr_matrix = dataset1.corr(method = 'spearman')\n",
    "  for fea in numerical_chosen_features:\n",
    "    corr_matrix = dataset.corr(method = 'spearman')\n",
    "    \n",
    "  for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "      if (my_abs(corr_matrix.iloc[i, j]) >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "        colname = corr_matrix.columns[i]\n",
    "        col_corr.add(colname)\n",
    "        if colname in dataset.columns:\n",
    "          del dataset[colname] \n",
    "  return dataset\n",
    "\n",
    "\n",
    "####################\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "#################### Data splitting\n",
    "def data_prep_ML(df, label_name):\n",
    "    y = pdf[label_name]\n",
    "    X = data\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=52, shuffle=True)\n",
    "    \n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority',random_state=52)\n",
    "    X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
    "    \n",
    "    X_train = X_under\n",
    "    y_train = y_under\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1db5373a-fa7d-4703-b4b9-dbd5e84a6259",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Categorical_chosen_features = categorical\n",
    "numerical_chosen_features = numerical + ['first_who',\"Total\",'Vaccination_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64b07180-ff85-4298-8e59-5f1ba6d1862c",
     "showTitle": true,
     "title": "Defining the features and imputations"
    }
   },
   "outputs": [],
   "source": [
    "hot_columns = []\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "Hotcoder_pipe = Pipeline([\n",
    "  ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "  ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "  ('imputer', SimpleImputer(strategy='constant',fill_value=0))\n",
    "])\n",
    "\n",
    "numerical_pipe = Pipeline([\n",
    "  ('imputer', IterativeImputer(random_state=52)),\n",
    "  ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc3d9ac9-ff17-493d-bfa0-290375cb3808",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "label_name = 'bi_severity_7'\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_prep_ML(pdf, label_name)\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(X_train)\n",
    " \n",
    "X_train_v1 = preprocessor.transform(X_train)\n",
    "X_test_v1 = preprocessor.transform(X_test)\n",
    "  \n",
    "ml = Pipeline([('preprocess', preprocessor),\n",
    "('classifier',RandomForestClassifier(class_weight=\"balanced\",random_state=52))])\n",
    "  \n",
    "ohe = (ml.named_steps['preprocess'])\n",
    "\n",
    "feature_names = np.r_[ Categorical_chosen_features, numerical_chosen_features]\n",
    "  \n",
    "X_train_v2 = pd.DataFrame(X_train_v1, columns=feature_names)\n",
    "X_test_v2 = pd.DataFrame(X_test_v1, columns=feature_names)\n",
    "#################################################################Lasso Tuning\n",
    "#from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#model = LogisticRegression(random_state=52)\n",
    "#solvers = ['liblinear','saga']\n",
    "#penalty = ['l1']\n",
    "#c_values = [2,1,0.1]\n",
    "## define grid search\n",
    "#cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=52)\n",
    "#grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "#grid_search = GridSearchCV(estimator=model, param_grid=grid, cv=cv, scoring='roc_auc')\n",
    "#grid_result = grid_search.fit(X_test_v2, y_test)\n",
    "## summarize results\n",
    "#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "#means = grid_result.cv_results_['mean_test_score']\n",
    "#stds = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eaf97ff4-7f63-4b6a-bb0f-929756c6d97c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "############################################################# Feature Selection\n",
    "\n",
    "#FS = SelectFromModel(LinearSVC(C=1 ,penalty='l1',dual=False,max_iter=1000)).fit(X_train_v2, y_train) ###l1 regularization\n",
    "FS = SelectFromModel(LogisticRegression(random_state=52,C=0.1, penalty='l1',solver='liblinear')).fit(X_train_v2, y_train) #lasso\n",
    "#FS = PCA(n_components=44).fit(X_train_v2, y_train)\n",
    "#FS = FactorAnalyzer(50, rotation=None).fit(X_train_v2, y_train)\n",
    "#FS = SelectFromModel(ExtraTreesClassifier(random_state=52,n_estimators=100)).fit(X_train_v2, y_train)\n",
    "\n",
    "#data_sevda=correlation(X_train_v2, 0.7)\n",
    "\n",
    "X_train_sel1 = FS.transform(X_train_v2)\n",
    "X_test_sel1 = FS.transform(X_test_v2)\n",
    "#X_train_sel1 = X_train_v2\n",
    "#X_test_sel1 = X_test_v2\n",
    "\n",
    "#X_train_sel = FS.transform(X_train_v2)\n",
    "#X_test_sel = FS.transform(X_test_v2)\n",
    "X_train_sel = X_train_v2\n",
    "X_test_sel = X_test_v2\n",
    "\n",
    "\n",
    "removed_feats = X_train_v2.columns[(FS.estimator_.coef_ == 0).ravel().tolist()]\n",
    "removed_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d525550c-e0ea-4575-b1d4-8dea83d73a4d",
     "showTitle": true,
     "title": "XGB Hyperparameter tuning"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "               \"gamma\" : [0.1, 0.3, 0.5, 1],\n",
    "               \"max_depth\": [7, 10],\n",
    "               \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.4, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [1000]}\n",
    "\n",
    "\n",
    "XB = XGBClassifier(booster='gbtree',objective = 'binary:logistic',use_label_encoder=False)\n",
    "XB_search = RandomizedSearchCV(XB, param_distributions = parameters, scoring = \"roc_auc\" ,cv = 5,n_iter = 100,random_state = 52)\n",
    "#XB_search = GridSearchCV(XB, param_grid = parameters, scoring = \"roc_auc\",cv = 10)\n",
    "XB_search.fit(X_train_sel, y_train)\n",
    "\n",
    "XB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44fdbe2e-3ddf-4c71-8eb3-f54be7cf2edc",
     "showTitle": true,
     "title": "Random Forest Hyperparameter tuning"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': [1000],\n",
    "               'max_depth': [4, 7, 10],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "#RF_search = RandomizedSearchCV(estimator = RF, param_distributions = parameters, scoring = \"f1\",n_iter = 100, cv =10, random_state=52)\n",
    "RF_search = GridSearchCV(RF, param_grid = parameters, scoring = \"roc_auc\" ,cv = 5)\n",
    "RF_search.fit(X_train_sel, y_train)\n",
    "\n",
    "RF_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73a0544e-df4c-43ce-9076-f96b560042a1",
     "showTitle": true,
     "title": "GB Hyperparameter tuning"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [5,7,10],\n",
    "              'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    " \n",
    "GB = GradientBoostingClassifier()\n",
    "GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"roc_auc\",cv=5, n_iter=100,random_state=52)\n",
    "GB_search.fit(X_train_sel, y_train)\n",
    "\n",
    "GB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce8572b2-253d-4d20-a2b3-ec8b3c571d57",
     "showTitle": true,
     "title": "AdaBoost Hyperparameter tuning"
    }
   },
   "outputs": [],
   "source": [
    "parameters={'n_estimators':[100, 500, 900, 1100, 1500],'learning_rate':[.001,0.01,.1]}\n",
    "\n",
    "Ada=AdaBoostClassifier()\n",
    "#Ada_search=RandomizedSearchCV(estimator = Ada, param_distributions = parameters,scoring = \"f1\",n_iter = 100, cv =10, random_state=52)\n",
    "Ada_search=GridSearchCV(Ada, param_grid = parameters, scoring = \"roc_auc\",cv = 10)\n",
    "Ada_search.fit(X_train_sel, y_train)\n",
    "\n",
    "Ada_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0a8eec3-db88-41e3-9081-0a938ef1f6f1",
     "showTitle": true,
     "title": "SVM Hyperparameter tuning"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': ['scale','auto'], \n",
    "              'kernel': ['rbf']}  \n",
    "  \n",
    "SVM_search = RandomizedSearchCV(estimator = SVC(), param_distributions=parameters,scoring = \"roc_auc\",refit = True, cv =10, random_state=52) \n",
    "SVM_search.fit(X_train_sel, y_train)\n",
    "\n",
    "SVM_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0b14c0d-5334-4a6f-971c-6e15d0e9d2bc",
     "showTitle": true,
     "title": "Threshold tuning"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# manually add the intercept\n",
    "data['intercept'] = 1.0\n",
    "GB = GradientBoostingClassifier(random_state=52)\n",
    "\n",
    "GB.fit(X_train_sel,y_train)\n",
    "pred_res = GB.predict(X_test_sel)\n",
    "pred = GB.predict_proba(X_test_sel)\n",
    "\n",
    "fpr, tpr, thresholds =roc_curve(y_test, pred[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)\n",
    "####################################\n",
    "i = np.arange(len(tpr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "# Plot tpr vs 1-fpr\n",
    "fig, ax = pl.subplots()\n",
    "pl.plot(roc['tpr'])\n",
    "pl.plot(roc['1-fpr'], color = 'red')\n",
    "pl.xlabel('1-False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('Receiver operating characteristic')\n",
    "#ax.set_xticklabels([])\n",
    "#ax.set_yticklabels([])\n",
    "\n",
    "\n",
    "##################\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-fpr, index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc[roc.tf == roc.tf.max()]\n",
    "    #roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return roc_t['threshold'] \n",
    "\n",
    "# Find optimal probability threshold\n",
    "threshold = Find_Optimal_Cutoff(y_test, pred[:,1])\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0f8f0e2-883d-4998-891d-ef9fef4d307f",
     "showTitle": true,
     "title": "Models"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "def run_cv_models(data):\n",
    "  k=10\n",
    "  skf = StratifiedKFold(n_splits=10)\n",
    "  scoring = ['accuracy' ,'balanced_accuracy','precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc', 'neg_mean_squared_error']\n",
    "  scores = defaultdict(list)\n",
    "#######################################\n",
    "  # Gradient Boosting\n",
    "\n",
    "  GB = GradientBoostingClassifier(random_state=52)\n",
    "  scores = cross_validate(GB, X_train_sel, y_train, scoring=scoring, cv=k)\n",
    "  sorted(scores.keys())\n",
    "  GB_fit_time = scores['fit_time'].mean()\n",
    "  GB_score_time = scores['score_time'].mean()\n",
    "  GB_accuracy = scores['test_accuracy'].mean()\n",
    "  GB_accuracy_std = scores['test_accuracy'].std()\n",
    "  GB_balanced_accuracy = scores['test_balanced_accuracy'].mean()\n",
    "  GB_balanced_accuracy_std = scores['test_balanced_accuracy'].std()\n",
    "  GB_precision = scores['test_precision_macro'].mean()\n",
    "  GB_precision_std = scores['test_precision_macro'].std()\n",
    "  GB_recall = scores['test_recall_macro'].mean()\n",
    "  GB_recall_std = scores['test_recall_macro'].std()\n",
    "  GB_f1 = scores['test_f1_weighted'].mean()\n",
    "  GB_f1_std = scores['test_f1_weighted'].std()\n",
    "  GB_roc = scores['test_roc_auc'].mean()\n",
    "  GB_roc_std = scores['test_roc_auc'].std()\n",
    "  GB_sem = stats.sem(scores['test_roc_auc'])\n",
    "    #\n",
    "  GB.fit(X_train_sel,y_train)\n",
    "  #pred_res = GB.predict(X_test_sel)\n",
    "  pred = GB.predict_proba(X_test_sel)\n",
    "  threhold = 0.553591\n",
    "  pred_res = (pred[:,1] >= threhold).astype('int')\n",
    "  \n",
    "  roc_auc = compute_auc(pred, y_test)\n",
    "  GB_Test_AUC = roc_auc\n",
    "  #\n",
    "  GB_TP = compute_performance(pred_res, y_test)[0]\n",
    "  GB_FP = compute_performance(pred_res, y_test)[1]\n",
    "  GB_TN = compute_performance(pred_res, y_test)[2]\n",
    "  GB_FN = compute_performance(pred_res, y_test)[3]\n",
    "  GB_Population = compute_performance(pred_res, y_test)[4]\n",
    "  GB_Prevalence = compute_performance(pred_res, y_test)[5]\n",
    "  GB_Accuracy = compute_performance(pred_res, y_test)[6]\n",
    "  GB_Precision = compute_performance(pred_res, y_test)[7]\n",
    "  GB_NPV = compute_performance(pred_res, y_test)[8]\n",
    "  GB_FDR = compute_performance(pred_res, y_test)[9]\n",
    "  GB_FOR = compute_performance(pred_res, y_test)[10]\n",
    "  GB_check_Pos = compute_performance(pred_res, y_test)[11]\n",
    "  GB_check_Neg = compute_performance(pred_res, y_test)[12]\n",
    "  GB_Recall = compute_performance(pred_res, y_test)[13]\n",
    "  GB_FPR = compute_performance(pred_res, y_test)[14]\n",
    "  GB_FNR = compute_performance(pred_res, y_test)[15]\n",
    "  GB_TNR = compute_performance(pred_res, y_test)[16]\n",
    "  GB_check_Pos2 = compute_performance(pred_res, y_test)[17]\n",
    "  GB_check_Neg2 = compute_performance(pred_res, y_test)[18]\n",
    "  GB_LRPos = compute_performance(pred_res, y_test)[19]\n",
    "  GB_LRNeg = compute_performance(pred_res, y_test)[20]\n",
    "  GB_DOR = compute_performance(pred_res, y_test)[21]\n",
    "  GB_F1 = compute_performance(pred_res, y_test)[22]\n",
    "  GB_MCC = compute_performance(pred_res, y_test)[23]\n",
    "  GB_BM = compute_performance(pred_res, y_test)[24]\n",
    "  GB_MK = compute_performance(pred_res, y_test)[25]\n",
    "  GB_Specificity = compute_performance(pred_res, y_test)[26]\n",
    "  GB_Youden = compute_performance(pred_res, y_test)[27]\n",
    "  #\n",
    "  precision, recall, thresholds = precision_recall_curve(y_test, pred_res)\n",
    "  GB_PR_AUC_test = AUC(recall, precision)\n",
    "############################################################    \n",
    "  # Logistic Regression\n",
    "  LR = LogisticRegression(random_state=52,penalty='l1', solver='liblinear')\n",
    "  scores = cross_validate(LR, X_train_sel1, y_train, scoring=scoring, cv=k)\n",
    "  sorted(scores.keys())\n",
    "  LR_fit_time = scores['fit_time'].mean()\n",
    "  LR_score_time = scores['score_time'].mean()\n",
    "  LR_accuracy = scores['test_accuracy'].mean()\n",
    "  LR_accuracy_std = scores['test_accuracy'].std()\n",
    "  LR_balanced_accuracy = scores['test_balanced_accuracy'].mean()\n",
    "  LR_balanced_accuracy_std = scores['test_balanced_accuracy'].std()\n",
    "  LR_precision = scores['test_precision_macro'].mean()\n",
    "  LR_precision_std = scores['test_precision_macro'].std()\n",
    "  LR_recall = scores['test_recall_macro'].mean()\n",
    "  LR_recall_std = scores['test_recall_macro'].std()\n",
    "  LR_f1 = scores['test_f1_weighted'].mean()\n",
    "  LR_f1_std = scores['test_f1_weighted'].std()\n",
    "  LR_roc = scores['test_roc_auc'].mean()\n",
    "  LR_roc_std = scores['test_roc_auc'].std()\n",
    "  LR_sem = stats.sem(scores['test_roc_auc'])\n",
    "  #\n",
    "  LR.fit(X_train_sel1,y_train)\n",
    "  #LR_Test_Acc = LR.score(X_test_sel, y_test)\n",
    "  #pred_res = LR.predict(X_test_sel1)\n",
    "  pred = LR.predict_proba(X_test_sel1)\n",
    "  threhold = 0.47753781057995065\n",
    "  pred_res = (pred[:,1] >= threhold).astype('int')\n",
    "\n",
    "  roc_auc = compute_auc(pred, y_test)\n",
    "  LR_Test_AUC = roc_auc\n",
    "  #\n",
    "  LR_TP = compute_performance(pred_res, y_test)[0]\n",
    "  LR_FP = compute_performance(pred_res, y_test)[1]\n",
    "  LR_TN = compute_performance(pred_res, y_test)[2]\n",
    "  LR_FN = compute_performance(pred_res, y_test)[3]\n",
    "  LR_Population = compute_performance(pred_res, y_test)[4]\n",
    "  LR_Prevalence = compute_performance(pred_res, y_test)[5]\n",
    "  LR_Accuracy = compute_performance(pred_res, y_test)[6]\n",
    "  LR_Precision = compute_performance(pred_res, y_test)[7]\n",
    "  LR_NPV = compute_performance(pred_res, y_test)[8]\n",
    "  LR_FDR = compute_performance(pred_res, y_test)[9]\n",
    "  LR_FOR = compute_performance(pred_res, y_test)[10]\n",
    "  LR_check_Pos = compute_performance(pred_res, y_test)[11]\n",
    "  LR_check_Neg = compute_performance(pred_res, y_test)[12]\n",
    "  LR_Recall = compute_performance(pred_res, y_test)[13]\n",
    "  LR_FPR = compute_performance(pred_res, y_test)[14]\n",
    "  LR_FNR = compute_performance(pred_res, y_test)[15]\n",
    "  LR_TNR = compute_performance(pred_res, y_test)[16]\n",
    "  LR_check_Pos2 = compute_performance(pred_res, y_test)[17]\n",
    "  LR_check_Neg2 = compute_performance(pred_res, y_test)[18]\n",
    "  LR_LRPos = compute_performance(pred_res, y_test)[19]\n",
    "  LR_LRNeg = compute_performance(pred_res, y_test)[20]\n",
    "  LR_DOR = compute_performance(pred_res, y_test)[21]\n",
    "  LR_F1 = compute_performance(pred_res, y_test)[22]\n",
    "  LR_MCC = compute_performance(pred_res, y_test)[23]\n",
    "  LR_BM = compute_performance(pred_res, y_test)[24]\n",
    "  LR_MK = compute_performance(pred_res, y_test)[25]\n",
    "  LR_Specificity = compute_performance(pred_res, y_test)[26]\n",
    "  LR_Youden = compute_performance(pred_res, y_test)[27]\n",
    "  #\n",
    "  precision, recall, thresholds = precision_recall_curve(y_test, pred_res)\n",
    "  LR_PR_AUC_test = AUC(recall, precision)\n",
    "################################################\n",
    "    # DT\n",
    "  DT = AdaBoostClassifier(random_state=52,n_estimators= 1500, learning_rate= 0.01)\n",
    "  scores = cross_validate(DT, X_train_sel, y_train, scoring=scoring, cv=k)\n",
    "  sorted(scores.keys())\n",
    "  DT_fit_time = scores['fit_time'].mean()\n",
    "  DT_score_time = scores['score_time'].mean()\n",
    "  DT_accuracy = scores['test_accuracy'].mean()\n",
    "  DT_accuracy_std = scores['test_accuracy'].std()\n",
    "  DT_balanced_accuracy = scores['test_balanced_accuracy'].mean()\n",
    "  DT_balanced_accuracy_std = scores['test_balanced_accuracy'].std()\n",
    "  DT_precision = scores['test_precision_macro'].mean()\n",
    "  DT_precision_std = scores['test_precision_macro'].std()\n",
    "  DT_recall = scores['test_recall_macro'].mean()\n",
    "  DT_recall_std = scores['test_recall_macro'].std()\n",
    "  DT_f1 = scores['test_f1_weighted'].mean()\n",
    "  DT_f1_std = scores['test_f1_weighted'].std()\n",
    "  DT_roc = scores['test_roc_auc'].mean()\n",
    "  DT_roc_std = scores['test_roc_auc'].std()\n",
    "  DT_sem = stats.sem(scores['test_roc_auc'])\n",
    "    #\n",
    "  DT.fit(X_train_sel,y_train)\n",
    "  #pred_res = DT.predict(X_test_sel)\n",
    "  pred = DT.predict_proba(X_test_sel)\n",
    "  threhold = 0.49747962085265024\n",
    "  pred_res = (pred[:,1] >= threhold).astype('int')\n",
    "  \n",
    "  roc_auc = compute_auc(pred, y_test)\n",
    "  DT_Test_AUC = roc_auc\n",
    "  #\n",
    "  DT_TP = compute_performance(pred_res, y_test)[0]\n",
    "  DT_FP = compute_performance(pred_res, y_test)[1]\n",
    "  DT_TN = compute_performance(pred_res, y_test)[2]\n",
    "  DT_FN = compute_performance(pred_res, y_test)[3]\n",
    "  DT_Population = compute_performance(pred_res, y_test)[4]\n",
    "  DT_Prevalence = compute_performance(pred_res, y_test)[5]\n",
    "  DT_Accuracy = compute_performance(pred_res, y_test)[6]\n",
    "  DT_Precision = compute_performance(pred_res, y_test)[7]\n",
    "  DT_NPV = compute_performance(pred_res, y_test)[8]\n",
    "  DT_FDR = compute_performance(pred_res, y_test)[9]\n",
    "  DT_FOR = compute_performance(pred_res, y_test)[10]\n",
    "  DT_check_Pos = compute_performance(pred_res, y_test)[11]\n",
    "  DT_check_Neg = compute_performance(pred_res, y_test)[12]\n",
    "  DT_Recall = compute_performance(pred_res, y_test)[13]\n",
    "  DT_FPR = compute_performance(pred_res, y_test)[14]\n",
    "  DT_FNR = compute_performance(pred_res, y_test)[15]\n",
    "  DT_TNR = compute_performance(pred_res, y_test)[16]\n",
    "  DT_check_Pos2 = compute_performance(pred_res, y_test)[17]\n",
    "  DT_check_Neg2 = compute_performance(pred_res, y_test)[18]\n",
    "  DT_LRPos = compute_performance(pred_res, y_test)[19]\n",
    "  DT_LRNeg = compute_performance(pred_res, y_test)[20]\n",
    "  DT_DOR = compute_performance(pred_res, y_test)[21]\n",
    "  DT_F1 = compute_performance(pred_res, y_test)[22]\n",
    "  DT_MCC = compute_performance(pred_res, y_test)[23]\n",
    "  DT_BM = compute_performance(pred_res, y_test)[24]\n",
    "  DT_MK = compute_performance(pred_res, y_test)[25]\n",
    "  DT_Specificity = compute_performance(pred_res, y_test)[26]\n",
    "  DT_Youden = compute_performance(pred_res, y_test)[27]\n",
    "  #\n",
    "  precision, recall, thresholds = precision_recall_curve(y_test, pred_res)\n",
    "  DT_PR_AUC_test = AUC(recall, precision)\n",
    "#######################################\n",
    "  #RF\n",
    "  RF =  RandomForestClassifier(random_state=52,n_estimators=1000,max_depth=10,min_samples_split=5,min_samples_leaf=4,bootstrap= True)\n",
    "  scores = cross_validate(RF, X_train_sel, y_train, scoring=scoring, cv=k)\n",
    "  sorted(scores.keys())\n",
    "  RF_fit_time = scores['fit_time'].mean()\n",
    "  RF_score_time = scores['score_time'].mean()\n",
    "  RF_accuracy = scores['test_accuracy'].mean()\n",
    "  RF_accuracy_std = scores['test_accuracy'].std()\n",
    "  RF_balanced_accuracy = scores['test_balanced_accuracy'].mean()\n",
    "  RF_balanced_accuracy_std = scores['test_balanced_accuracy'].std()\n",
    "  RF_precision = scores['test_precision_macro'].mean()\n",
    "  RF_precision_std = scores['test_precision_macro'].std()\n",
    "  RF_recall = scores['test_recall_macro'].mean()\n",
    "  RF_recall_std = scores['test_recall_macro'].std()\n",
    "  RF_f1 = scores['test_f1_weighted'].mean()\n",
    "  RF_f1_std = scores['test_f1_weighted'].std()\n",
    "  RF_roc = scores['test_roc_auc'].mean()\n",
    "  RF_roc_std = scores['test_roc_auc'].std()\n",
    "  RF_sem = stats.sem(scores['test_roc_auc'])\n",
    "  #\n",
    "  RF.fit(X_train_sel,y_train)\n",
    "  #RF_Test_Acc = RF.score(X_test_sel, y_test)\n",
    "  #pred_res = RF.predict(X_test_sel)\n",
    "  pred = RF.predict_proba(X_test_sel)\n",
    "  threhold = 0.4810214565638289\n",
    "  pred_res = (pred[:,1] >= threhold).astype('int')\n",
    "  \n",
    "  roc_auc = compute_auc(pred, y_test)\n",
    "  RF_Test_AUC = roc_auc\n",
    "  #\n",
    "  RF_TP = compute_performance(pred_res, y_test)[0]\n",
    "  RF_FP = compute_performance(pred_res, y_test)[1]\n",
    "  RF_TN = compute_performance(pred_res, y_test)[2]\n",
    "  RF_FN = compute_performance(pred_res, y_test)[3]\n",
    "  RF_Population = compute_performance(pred_res, y_test)[4]\n",
    "  RF_Prevalence = compute_performance(pred_res, y_test)[5]\n",
    "  RF_Accuracy = compute_performance(pred_res, y_test)[6]\n",
    "  RF_Precision = compute_performance(pred_res, y_test)[7]\n",
    "  RF_NPV = compute_performance(pred_res, y_test)[8]\n",
    "  RF_FDR = compute_performance(pred_res, y_test)[9]\n",
    "  RF_FOR = compute_performance(pred_res, y_test)[10]\n",
    "  RF_check_Pos = compute_performance(pred_res, y_test)[11]\n",
    "  RF_check_Neg = compute_performance(pred_res, y_test)[12]\n",
    "  RF_Recall = compute_performance(pred_res, y_test)[13]\n",
    "  RF_FPR = compute_performance(pred_res, y_test)[14]\n",
    "  RF_FNR = compute_performance(pred_res, y_test)[15]\n",
    "  RF_TNR = compute_performance(pred_res, y_test)[16]\n",
    "  RF_check_Pos2 = compute_performance(pred_res, y_test)[17]\n",
    "  RF_check_Neg2 = compute_performance(pred_res, y_test)[18]\n",
    "  RF_LRPos = compute_performance(pred_res, y_test)[19]\n",
    "  RF_LRNeg = compute_performance(pred_res, y_test)[20]\n",
    "  RF_DOR = compute_performance(pred_res, y_test)[21]\n",
    "  RF_F1 = compute_performance(pred_res, y_test)[22]\n",
    "  RF_MCC = compute_performance(pred_res, y_test)[23]\n",
    "  RF_BM = compute_performance(pred_res, y_test)[24]\n",
    "  RF_MK = compute_performance(pred_res, y_test)[25]\n",
    "  RF_Specificity = compute_performance(pred_res, y_test)[26]\n",
    "  RF_Youden = compute_performance(pred_res, y_test)[27]\n",
    "  #\n",
    "  precision, recall, thresholds = precision_recall_curve(y_test, pred_res)\n",
    "  RF_PR_AUC_test = AUC(recall, precision)\n",
    "    ##########################\n",
    "    # faster models\n",
    "  cv_results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'AdaBoost', 'Random Forest','Gradient Boosting'],\n",
    "    'Train Fitting time': [LR_fit_time, DT_fit_time, RF_fit_time, GB_fit_time],\n",
    "    'Train Scoring time': [LR_score_time, DT_score_time, RF_score_time, GB_score_time],\n",
    "    'Train Accuracy': [LR_accuracy, DT_accuracy, RF_accuracy, GB_accuracy],\n",
    "    'Train Accuracy STD': [LR_accuracy_std, DT_accuracy_std, RF_accuracy_std, GB_accuracy_std],\n",
    "    'Train Balanced Accuracy': [LR_balanced_accuracy, DT_balanced_accuracy, RF_balanced_accuracy, GB_balanced_accuracy],\n",
    "    'Train Balanced Accuracy STD': [LR_balanced_accuracy_std, DT_balanced_accuracy_std, RF_balanced_accuracy_std, GB_balanced_accuracy_std],\n",
    "    'Train Precision': [LR_precision, DT_precision, RF_precision, GB_precision],\n",
    "    'Train Precision STD': [LR_precision_std, DT_precision_std, RF_precision_std, GB_precision_std],\n",
    "    'Train Recall': [LR_recall, DT_recall, RF_recall, GB_recall],\n",
    "    'Train Recall STD': [LR_recall_std, DT_recall_std, RF_recall_std, GB_recall_std],\n",
    "    'Train F1_score': [LR_f1, DT_f1, RF_f1, GB_f1],\n",
    "    'Train F1_score STD': [LR_f1_std, DT_f1_std, RF_f1_std, GB_f1_std],\n",
    "    'Train AUC_ROC': [LR_roc, DT_roc, RF_roc, GB_roc],\n",
    "    'Train AUC_ROC STD': [LR_roc_std, DT_roc_std, RF_roc_std, GB_roc_std],\n",
    "    'Train Error': [LR_sem, DT_sem, RF_sem, GB_sem],\n",
    "    'Test AUC': [LR_Test_AUC,DT_Test_AUC,RF_Test_AUC,GB_Test_AUC],\n",
    "    'Test PR_AUC': [LR_PR_AUC_test, DT_PR_AUC_test, RF_PR_AUC_test, GB_PR_AUC_test],\n",
    "    'Test TP':[LR_TP,DT_TP,RF_TP,GB_TP],\n",
    "    'Test FP':[LR_FP,DT_FP,RF_FP,GB_FP],\n",
    "    'Test TN':[LR_TN,DT_TN,RF_TN,GB_TN],\n",
    "    'Test FN':[LR_FN,DT_FN,RF_FN,GB_FN],\n",
    "    'Test Population':[LR_Population,DT_Population,RF_Population,GB_Population] ,\n",
    "    'Test Prevalence': [LR_Prevalence,DT_Prevalence,RF_Prevalence,GB_Prevalence],\n",
    "    'Test Accuracy': [LR_Accuracy,DT_Accuracy,RF_Accuracy,GB_Accuracy],\n",
    "    'Test Precision': [LR_Precision,DT_Precision,RF_Precision,GB_Precision],\n",
    "    'Test Recall':[LR_Recall,DT_Recall,RF_Recall,GB_Recall],\n",
    "    'Test Specificity':[LR_Specificity,DT_Specificity,RF_Specificity,GB_Specificity],\n",
    "    'Test NPV':[LR_NPV,DT_NPV,RF_NPV,GB_NPV],\n",
    "    'Test FDR':[LR_FDR,DT_FDR,RF_FDR,GB_FDR],\n",
    "    'Test FOR':[LR_FOR,DT_FOR,RF_FOR,GB_FOR],\n",
    "    'Test check_Pos':[LR_check_Pos,DT_check_Pos,RF_check_Pos,GB_check_Pos],\n",
    "    'Test check_Neg':[LR_check_Neg,DT_check_Neg,RF_check_Neg,GB_check_Neg],\n",
    "    'Test FPR':[LR_FPR,DT_FPR,RF_FPR,GB_FPR],\n",
    "    'Test FNR':[LR_FNR,DT_FNR,RF_FNR,GB_FNR],\n",
    "    'Test TNR':[LR_TNR,DT_TNR,RF_TNR,GB_TNR],\n",
    "    'Test check_Pos2':[LR_check_Pos2,DT_check_Pos2,RF_check_Pos2,GB_check_Pos2],\n",
    "    'Test check_Neg2':[LR_check_Neg2,DT_check_Neg2,RF_check_Neg2,GB_check_Neg2],\n",
    "    'Test LRPos':[LR_LRPos,DT_LRPos,RF_LRPos,GB_LRPos],\n",
    "    'Test LRNeg':[LR_LRNeg,DT_LRNeg,RF_LRNeg,GB_LRNeg],\n",
    "    'Test DOR':[LR_DOR,DT_DOR,RF_DOR,GB_DOR],\n",
    "    'Test F1':[LR_F1,DT_F1,RF_F1,GB_F1],\n",
    "    'Test MCC':[LR_MCC,DT_MCC,RF_MCC,GB_MCC],\n",
    "    'Test BM':[LR_BM,DT_BM,RF_BM,GB_BM],\n",
    "    'Test MK':[LR_MK,DT_MK,RF_MK,GB_MK],\n",
    "    'Test Youden':[LR_Youden,DT_Youden,RF_Youden,GB_Youden]\n",
    "  },   columns=['Model', 'Train Fitting time', 'Train Scoring time', 'Train Accuracy','Train Accuracy STD', 'Train Balanced Accuracy','Train Balanced Accuracy STD','Train Precision', 'Train Precision STD', 'Train Recall', 'Train Recall STD', 'Train F1_score', 'Train F1_score STD', 'Train AUC_ROC', 'Train AUC_ROC STD', 'Train Error','Test AUC','Test PR_AUC','Test TP', 'Test FP', 'Test TN', 'Test FN', 'Test Population' ,'Test Prevalence' ,'Test Accuracy' ,'Test Precision' ,'Test Recall','Test Specificity', 'Test NPV','Test FDR','Test FOR','Test check_Pos','Test check_Neg','Test FPR','Test FNR','Test TNR','Test check_Pos2','Test check_Neg2','Test LRPos','Test LRNeg','Test DOR','Test F1','Test MCC', 'Test BM','Test MK','Test Youden'])\n",
    "  \n",
    "  return cv_results\n",
    "\n",
    "CV10_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cad1543-2bd0-4ecb-a093-4d4bda76d294",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_cv_models(pdf).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3af8c2df-3bf1-4bc5-baf9-886cc7a757d5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0497de29-7ff2-4ee8-883b-e4e68bab530d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_sel = X_train_sel.rename({\n",
    "'sex': 'Sex',\n",
    "'age': 'Age',\n",
    "'race':'Race',\n",
    "'first_who': \"Oxygen Mode\",\n",
    "'htn': 'Hypertension',\n",
    "'heart_conditions': 'Cardiovascular conditions', \n",
    "'asthma':   'Asthma',\n",
    "'n_visit': 'Number of visit prior to COVID test',\n",
    "'hispanic': 'Ethnicity',\n",
    "'COPD': 'COPD',\n",
    "'cancer': 'Malignancy',\n",
    "'stroke' : 'Stroke', \n",
    "'liver_disease' : 'Liver disease', \n",
    "'ckd' : 'Chronic kidney disease', \n",
    "'hld': 'Hyperlipidemia/Dyslipidemia',  \n",
    "'osa': 'Obstructive sleep apnea', \n",
    "'diabetes2': 'Type 2 diabetes mellitus', \n",
    "'diabetes1': 'Type 1 diabetes mellitus',\n",
    "'diabetes': 'Diabetes',\n",
    "'sot': 'Solid organ transplant', \n",
    "'ics': 'Immunosuppression',\n",
    "'dementia': 'Dementia',\n",
    "'alzheimer':'Alzheimer',\n",
    "'Coronary_arteriosclerosis':'Coronary arteriosclerosis',\n",
    "'Heart_failure':'Heart failure',\n",
    "'Cardiomyopathy':'Cardiomyopathy',\n",
    "'BMI': 'BMI',\n",
    "'HR_max': 'HR (Maximum)',\n",
    "'HR_mean': 'HR (Mean)',\n",
    "'HR_min': 'HR (Minimum)',\n",
    "'HR_std': 'HR (Standard deviation)',\n",
    "'SBP_max': 'SBP (Maximum)',\n",
    "'SBP_mean': 'SBP (Mean)',\n",
    "'SBP_min': 'SBP (Minimum)', \n",
    "'SBP_std': 'SBP (Standard deviation)',\n",
    "'DBP_max': 'DBP (Maximum)',\n",
    "'DBP_mean': 'DBP (Mean)', \n",
    "'DBP_min': 'DBP (Minimum)', \n",
    "'DBP_std': 'DBP (Standard deviation)',\n",
    "'temp_max':'Temperature (Maximum)', \n",
    "'temp_mean':'Temperature (Mean)', \n",
    "'temp_min':'Temperature (Minimum)', \n",
    "'temp_std':'Temperature (Standard deviation)',\n",
    "'RR_max': 'RR (Maximum)',\n",
    "'RR_mean': 'RR (Mean)', \n",
    "'RR_min': 'RR (Minimum)', \n",
    "'RR_std': 'RR (Standard deviation)',\n",
    "'spo2_max': 'SPO2 (Maximum)',\n",
    "'spo2_mean': 'SPO2 (Mean)', \n",
    "'spo2_min': 'SPO2 (Min)', \n",
    "'spo2_std': 'SPO2 (Standard deviation)',\n",
    "'resultvalue_HCO3':'HCO3 (Mean)',\n",
    "  'resultvalue_CI':'CI (Mean)',\n",
    "  'resultvalue_BUN':'BUN (Mean)',\n",
    "  'resultvalue_PLT':'PLT (Mean)',\n",
    "  'resultvalue_eosabs':'EOSABS (Mean)',\n",
    "  'resultvalue_neuabs':'NEUABS (Mean)',\n",
    "  'resultvalue_ast':'AST (Mean)',\n",
    "  'resultvalue_alt':'ALT (Mean)',\n",
    "  'resultvalue_creatinine':'CREA (Mean)',\n",
    "  'resultvalue_potassium':'K (Mean)',\n",
    "  'resultvalue_alb':'ALB (Mean)',\n",
    "  'resultvalue_sodium':'NA (Mean)',\n",
    "  'resultvalue_HGB':'HGB (Mean)',\n",
    "  'resultvalue_HCT':'HCT (Mean)',\n",
    "  'resultvalue_lymph':'LYMPH (Mean)',\n",
    "  'resultvalue_WBC':'WBC (Mean)',\n",
    "  'resultvalue_calcium':'CA (Mean)',\n",
    "'resultvalue_RBC':'RBC (Mean)',\n",
    "  'resultvalue_Baso':'BASO (Mean)',\n",
    "  'resultvalue_Mono':'MONO (Mean)',\n",
    "  'resultvalue_Alkaline':'ALP (Mean)',\n",
    "  'resultvalue_Anion':'AGAP (Mean)',\n",
    "  'resultvalue_Bilirubin':'TBIL (Mean)',\n",
    "  'resultvalue_Globulin':'GLOB (Mean)',\n",
    "  'resultvalue_Protein':'Total Protein (Mean)',\n",
    "'resultvalue_Glucose':'GLU (Mean)',\n",
    "'Delta_RR':'RR (Delta)',\n",
    "'Delta_HR':'HR (Delta)',\n",
    "'Delta_TMP':'TMP (Delta)',\n",
    "'Vasso_use':'Vasopressors',\n",
    "'Total':'Number of Comorbidities',\n",
    "'count_dose':'Number of Vaccine Doses Administered',\n",
    "'Last_HR':'HR', \n",
    "  'Last_SBP':'SBP',\n",
    "  'Last_DBP':'DBP',\n",
    "  'Last_temp':'Temperature',\n",
    "  'Last_RR':'RR', \n",
    "  'Last_spo2':'SPO2',\n",
    "  'Last Measured HR':'HR', \n",
    "  'Last Measured SBP':'SBP',\n",
    "  'Last Measured DBP':'DBP',\n",
    "  'Last Measured Temperature':'Temperature',\n",
    "  'Last Measured RR':'RR', \n",
    "  'Last Measured SPO2':'SPO2',\n",
    "  'Last_RBC':'RBC', \n",
    "  'Last_wbc': 'WBC',\n",
    "  'Last_PLT': 'PLT',\n",
    "  'Last_HGB': 'HGB', \n",
    "  'Last_HCT': 'HCT',     \n",
    "  'Last_potassium': 'K',\n",
    "  'Last_sodium': 'NA',\n",
    "  'Last_HCO3': 'HCO3',\n",
    "  'Last_CI': 'CI',\n",
    "  'Last_creatinine': 'CREAT',\n",
    "  'Last_BUN': 'BUN',\n",
    "  'Last_Glucose': 'GLU',\n",
    "'ETHNICGROUP': 'Ethnic group',\n",
    "'Vaccination_status':'Vaccination status'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75994b99-9104-401e-93db-6ec4e98f6be3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test_sel = X_test_sel.rename({\n",
    "'sex': 'Sex',\n",
    "'age': 'Age',\n",
    "'race':'Race',\n",
    "'first_who': \"Oxygen Mode\",\n",
    "'htn': 'Hypertension',\n",
    "'heart_conditions': 'Cardiovascular conditions', \n",
    "'asthma':   'Asthma',\n",
    "'n_visit': 'Number of visit prior to COVID test',\n",
    "'hispanic': 'Ethnicity',\n",
    "'COPD': 'COPD',\n",
    "'cancer': 'Malignancy',\n",
    "'stroke' : 'Stroke', \n",
    "'liver_disease' : 'Liver disease', \n",
    "'ckd' : 'Chronic kidney disease', \n",
    "'hld': 'Hyperlipidemia/Dyslipidemia',  \n",
    "'osa': 'Obstructive sleep apnea', \n",
    "'diabetes2': 'Type 2 diabetes mellitus', \n",
    "'diabetes1': 'Type 1 diabetes mellitus',\n",
    "'diabetes': 'Diabetes',\n",
    "'sot': 'Solid organ transplant', \n",
    "'ics': 'Immunosuppression',\n",
    "'dementia': 'Dementia',\n",
    "'alzheimer':'Alzheimer',\n",
    "'Coronary_arteriosclerosis':'Coronary arteriosclerosis',\n",
    "'Heart_failure':'Heart failure',\n",
    "'Cardiomyopathy':'Cardiomyopathy',\n",
    "'BMI': 'BMI',\n",
    "'HR_max': 'HR (Maximum)',\n",
    "'HR_mean': 'HR (Mean)',\n",
    "'HR_min': 'HR (Minimum)',\n",
    "'HR_std': 'HR (Standard deviation)',\n",
    "'SBP_max': 'SBP (Maximum)',\n",
    "'SBP_mean': 'SBP (Mean)',\n",
    "'SBP_min': 'SBP (Minimum)', \n",
    "'SBP_std': 'SBP (Standard deviation)',\n",
    "'DBP_max': 'DBP (Maximum)',\n",
    "'DBP_mean': 'DBP (Mean)', \n",
    "'DBP_min': 'DBP (Minimum)', \n",
    "'DBP_std': 'DBP (Standard deviation)',\n",
    "'temp_max':'Temperature (Maximum)', \n",
    "'temp_mean':'Temperature (Mean)', \n",
    "'temp_min':'Temperature (Minimum)', \n",
    "'temp_std':'Temperature (Standard deviation)',\n",
    "'RR_max': 'RR (Maximum)',\n",
    "'RR_mean': 'RR (Mean)', \n",
    "'RR_min': 'RR (Minimum)', \n",
    "'RR_std': 'RR (Standard deviation)',\n",
    "'spo2_max': 'SPO2 (Maximum)',\n",
    "'spo2_mean': 'SPO2 (Mean)', \n",
    "'spo2_min': 'SPO2 (Min)', \n",
    "'spo2_std': 'SPO2 (Standard deviation)',\n",
    "'resultvalue_HCO3':'HCO3 (Mean)',\n",
    "  'resultvalue_CI':'CI (Mean)',\n",
    "  'resultvalue_BUN':'BUN (Mean)',\n",
    "  'resultvalue_PLT':'PLT (Mean)',\n",
    "  'resultvalue_eosabs':'EOSABS (Mean)',\n",
    "  'resultvalue_neuabs':'NEUABS (Mean)',\n",
    "  'resultvalue_ast':'AST (Mean)',\n",
    "  'resultvalue_alt':'ALT (Mean)',\n",
    "  'resultvalue_creatinine':'CREA (Mean)',\n",
    "  'resultvalue_potassium':'K (Mean)',\n",
    "  'resultvalue_alb':'ALB (Mean)',\n",
    "  'resultvalue_sodium':'NA (Mean)',\n",
    "  'resultvalue_HGB':'HGB (Mean)',\n",
    "  'resultvalue_HCT':'HCT (Mean)',\n",
    "  'resultvalue_lymph':'LYMPH (Mean)',\n",
    "  'resultvalue_WBC':'WBC (Mean)',\n",
    "  'resultvalue_calcium':'CA (Mean)',\n",
    "'resultvalue_RBC':'RBC (Mean)',\n",
    "  'resultvalue_Baso':'BASO (Mean)',\n",
    "  'resultvalue_Mono':'MONO (Mean)',\n",
    "  'resultvalue_Alkaline':'ALP (Mean)',\n",
    "  'resultvalue_Anion':'AGAP (Mean)',\n",
    "  'resultvalue_Bilirubin':'TBIL (Mean)',\n",
    "  'resultvalue_Globulin':'GLOB (Mean)',\n",
    "  'resultvalue_Protein':'Total Protein (Mean)',\n",
    "'resultvalue_Glucose':'GLU (Mean)',\n",
    "'Delta_RR':'RR (Delta)',\n",
    "'Delta_HR':'HR (Delta)',\n",
    "'Delta_TMP':'TMP (Delta)',\n",
    "'Vasso_use':'Vasopressors',\n",
    "'Total':'Number of Comorbidities',\n",
    "'count_dose':'Number of Vaccine Doses Administered',\n",
    "'Last_HR':'HR', \n",
    "  'Last_SBP':'SBP',\n",
    "  'Last_DBP':'DBP',\n",
    "  'Last_temp':'Temperature',\n",
    "  'Last_RR':'RR', \n",
    "  'Last_spo2':'SPO2',\n",
    "  'Last Measured HR':'HR', \n",
    "  'Last Measured SBP':'SBP',\n",
    "  'Last Measured DBP':'DBP',\n",
    "  'Last Measured Temperature':'Temperature',\n",
    "  'Last Measured RR':'RR', \n",
    "  'Last Measured SPO2':'SPO2',\n",
    "  'Last_RBC':'RBC', \n",
    "  'Last_wbc': 'WBC',\n",
    "  'Last_PLT': 'PLT',\n",
    "  'Last_HGB': 'HGB', \n",
    "  'Last_HCT': 'HCT',     \n",
    "  'Last_potassium': 'K',\n",
    "  'Last_sodium': 'NA',\n",
    "  'Last_HCO3': 'HCO3',\n",
    "  'Last_CI': 'CI',\n",
    "  'Last_creatinine': 'CREAT',\n",
    "  'Last_BUN': 'BUN',\n",
    "  'Last_Glucose': 'GLU',\n",
    "'ETHNICGROUP': 'Ethnic group',\n",
    "'Vaccination_status':'Vaccination status'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55cefe54-86cc-491e-bd02-5e004dca7904",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test = X_test.rename({\n",
    "'sex': 'Sex',\n",
    "'age': 'Age',\n",
    "'race':'Race',\n",
    "'first_who': \"Oxygen Mode\",\n",
    "'htn': 'Hypertension',\n",
    "'heart_conditions': 'Cardiovascular conditions', \n",
    "'asthma':   'Asthma',\n",
    "'n_visit': 'Number of visit prior to COVID test',\n",
    "'hispanic': 'Ethnicity',\n",
    "'COPD': 'COPD',\n",
    "'cancer': 'Malignancy',\n",
    "'stroke' : 'Stroke', \n",
    "'liver_disease' : 'Liver disease', \n",
    "'ckd' : 'Chronic kidney disease', \n",
    "'hld': 'Hyperlipidemia/Dyslipidemia',  \n",
    "'osa': 'Obstructive sleep apnea', \n",
    "'diabetes2': 'Type 2 diabetes mellitus', \n",
    "'diabetes1': 'Type 1 diabetes mellitus',\n",
    "'diabetes': 'Diabetes',\n",
    "'sot': 'Solid organ transplant', \n",
    "'ics': 'Immunosuppression',\n",
    "'dementia': 'Dementia',\n",
    "'alzheimer':'Alzheimer',\n",
    "'Coronary_arteriosclerosis':'Coronary arteriosclerosis',\n",
    "'Heart_failure':'Heart failure',\n",
    "'Cardiomyopathy':'Cardiomyopathy',\n",
    "'BMI': 'BMI',\n",
    "'HR_max': 'HR (Maximum)',\n",
    "'HR_mean': 'HR (Mean)',\n",
    "'HR_min': 'HR (Minimum)',\n",
    "'HR_std': 'HR (Standard deviation)',\n",
    "'SBP_max': 'SBP (Maximum)',\n",
    "'SBP_mean': 'SBP (Mean)',\n",
    "'SBP_min': 'SBP (Minimum)', \n",
    "'SBP_std': 'SBP (Standard deviation)',\n",
    "'DBP_max': 'DBP (Maximum)',\n",
    "'DBP_mean': 'DBP (Mean)', \n",
    "'DBP_min': 'DBP (Minimum)', \n",
    "'DBP_std': 'DBP (Standard deviation)',\n",
    "'temp_max':'Temperature (Maximum)', \n",
    "'temp_mean':'Temperature (Mean)', \n",
    "'temp_min':'Temperature (Minimum)', \n",
    "'temp_std':'Temperature (Standard deviation)',\n",
    "'RR_max': 'RR (Maximum)',\n",
    "'RR_mean': 'RR (Mean)', \n",
    "'RR_min': 'RR (Minimum)', \n",
    "'RR_std': 'RR (Standard deviation)',\n",
    "'spo2_max': 'SPO2 (Maximum)',\n",
    "'spo2_mean': 'SPO2 (Mean)', \n",
    "'spo2_min': 'SPO2 (Min)', \n",
    "'spo2_std': 'SPO2 (Standard deviation)',\n",
    "'resultvalue_HCO3':'HCO3 (Mean)',\n",
    "  'resultvalue_CI':'CI (Mean)',\n",
    "  'resultvalue_BUN':'BUN (Mean)',\n",
    "  'resultvalue_PLT':'PLT (Mean)',\n",
    "  'resultvalue_eosabs':'EOSABS (Mean)',\n",
    "  'resultvalue_neuabs':'NEUABS (Mean)',\n",
    "  'resultvalue_ast':'AST (Mean)',\n",
    "  'resultvalue_alt':'ALT (Mean)',\n",
    "  'resultvalue_creatinine':'CREA (Mean)',\n",
    "  'resultvalue_potassium':'K (Mean)',\n",
    "  'resultvalue_alb':'ALB (Mean)',\n",
    "  'resultvalue_sodium':'NA (Mean)',\n",
    "  'resultvalue_HGB':'HGB (Mean)',\n",
    "  'resultvalue_HCT':'HCT (Mean)',\n",
    "  'resultvalue_lymph':'LYMPH (Mean)',\n",
    "  'resultvalue_WBC':'WBC (Mean)',\n",
    "  'resultvalue_calcium':'CA (Mean)',\n",
    "'resultvalue_RBC':'RBC (Mean)',\n",
    "  'resultvalue_Baso':'BASO (Mean)',\n",
    "  'resultvalue_Mono':'MONO (Mean)',\n",
    "  'resultvalue_Alkaline':'ALP (Mean)',\n",
    "  'resultvalue_Anion':'AGAP (Mean)',\n",
    "  'resultvalue_Bilirubin':'TBIL (Mean)',\n",
    "  'resultvalue_Globulin':'GLOB (Mean)',\n",
    "  'resultvalue_Protein':'Total Protein (Mean)',\n",
    "'resultvalue_Glucose':'GLU (Mean)',\n",
    "'Delta_RR':'RR (Delta)',\n",
    "'Delta_HR':'HR (Delta)',\n",
    "'Delta_TMP':'TMP (Delta)',\n",
    "'Vasso_use':'Vasopressors',\n",
    "'Total':'Number of Comorbidities',\n",
    "'count_dose':'Number of Vaccine Doses Administered',\n",
    "'Last_HR':'HR', \n",
    "  'Last_SBP':'SBP',\n",
    "  'Last_DBP':'DBP',\n",
    "  'Last_temp':'Temperature',\n",
    "  'Last_RR':'RR', \n",
    "  'Last_spo2':'SPO2',\n",
    "  'Last Measured HR':'HR', \n",
    "  'Last Measured SBP':'SBP',\n",
    "  'Last Measured DBP':'DBP',\n",
    "  'Last Measured Temperature':'Temperature',\n",
    "  'Last Measured RR':'RR', \n",
    "  'Last Measured SPO2':'SPO2',\n",
    "  'Last_RBC':'RBC', \n",
    "  'Last_wbc': 'WBC',\n",
    "  'Last_PLT': 'PLT',\n",
    "  'Last_HGB': 'HGB', \n",
    "  'Last_HCT': 'HCT',     \n",
    "  'Last_potassium': 'K',\n",
    "  'Last_sodium': 'NA',\n",
    "  'Last_HCO3': 'HCO3',\n",
    "  'Last_CI': 'CI',\n",
    "  'Last_creatinine': 'CREAT',\n",
    "  'Last_BUN': 'BUN',\n",
    "  'Last_Glucose': 'GLU',\n",
    "'ETHNICGROUP': 'Ethnic group',\n",
    "'Vaccination_status':'Vaccination status'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4ac8ca5-8506-4bf7-9042-5030586f965b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "k=10\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc', 'neg_mean_squared_error']\n",
    "GB = GradientBoostingClassifier(random_state=52,learning_rate=0.01,max_depth=5,n_estimators=1000,min_samples_split=4,min_samples_leaf=1,max_features= 'log2')\n",
    "scores = cross_validate(GB, X_train_sel, y_train, scoring=scoring, cv=k)\n",
    "GB.fit(X_train_sel,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06f56886-6649-4ac4-a8f3-5a58eee7ee05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###SHAP ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f07f0bb4-b474-4e00-9452-69079c9cef72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#columns_sel = X_train_v2.columns[(FS.get_support())]\n",
    "columns_sel = X_train_sel.columns\n",
    "X_test_v3 = X_test_sel[columns_sel]\n",
    "X_test_v4 = X_test[columns_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a369dc8c-1175-43dd-8747-98784930683b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model_predict(data_asarray):\n",
    "  data_asframe =  pd.DataFrame(data_asarray, columns= columns_sel)\n",
    "  return GB.predict(data_asframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48d98fcc-1a57-4f4a-8140-c704285412bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Tree - Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b714d69c-73a4-43b9-96b6-cdb2be14717f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_values_Tree = shap.TreeExplainer(GB).shap_values(X_test_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d70d934e-485d-48ed-b391-63a8133ee9a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.installPyPI('yellowbrick')\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from yellowbrick.classifier import DiscriminationThreshold\n",
    "\n",
    "visualizer = DiscriminationThreshold(GB)\n",
    "\n",
    "visualizer.fit(X_train_sel, y_train)        # Fit the data to the visualizer\n",
    "#visualizer.grid(False)\n",
    "visualizer.show()           # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a439963b-96a6-422f-b6e9-323af33606ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.summary_plot(shap_values_Tree, X_test_v3, max_display=110,plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8da5c333-7bbd-43a3-bc0c-122c4858f53b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.summary_plot(shap_values_Tree, X_test_v3,max_display=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "541d3b6f-dbd2-4352-8f07-cdc0e67bdd68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.dependence_plot('Age', shap_values_Tree, X_test_v4, interaction_index=None,dot_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7889d157-f065-418b-b318-fec46fd7eef3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Violin plots\n",
    "shap.summary_plot(shap_values_Tree, X_test_v3,max_display=75,plot_type=\"layered_violin\", color='seismic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a40c4f9-f470-48dd-b59c-86cb03c2fb94",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### ELI5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8131a8e-bdef-449d-a3e8-72eaa6f3eeff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(GB, random_state=52,cv=10).fit(X_train_sel,y_train)\n",
    "eli5.show_weights(perm, feature_names = columns_sel.tolist(),top=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23ae8d6d-313d-48c6-9458-407b29655f01",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a1e5206-d0b6-4528-9df6-b8a8e14af349",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "k=10\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc', 'neg_mean_squared_error']\n",
    "#GB model\n",
    "GB =  GradientBoostingClassifier(random_state=52,learning_rate=0.001,max_depth=10,n_estimators=1000,min_samples_split=10,min_samples_leaf= 1,max_features= 'log2')\n",
    "scores = cross_validate(GB, X_train_sel, y_train, scoring=scoring, cv=k)\n",
    "GB.fit(X_train_sel,y_train)\n",
    "\n",
    "#RF model\n",
    "RF = RandomForestClassifier(random_state=52,n_estimators=1000,max_depth=10,min_samples_split=2,min_samples_leaf=1,bootstrap= True)\n",
    "scores = cross_validate(RF, X_train_sel, y_train, scoring=scoring, cv=k)\n",
    "RF.fit(X_train_sel,y_train)\n",
    "\n",
    "#XGB model\n",
    "#XB=XGBClassifier(random_state=52,booster='gbtree',learning_rate=0.01,objective='binary:logistic',n_estimators=1000,use_label_encoder=False,colsample_bytree=0.6, gamma= 0.5, max_depth=10, min_child_weight= 1, reg_alpha=0 ,reg_lambda=1.5,subsample=0.6)\n",
    "#scores = cross_validate(XB, X_train_sel, y_train, scoring=scoring, cv=k)\n",
    "#XB.fit(X_train_sel,y_train)\n",
    "\n",
    "#LR model\n",
    "LR = LogisticRegression(random_state=52,penalty='l1', solver='liblinear')\n",
    "scores = cross_validate(LR, X_train_sel1, y_train, scoring=scoring, cv=k)\n",
    "sorted(scores.keys())\n",
    "LR.fit(X_train_sel1,y_train)\n",
    "\n",
    "#Adaboost model\n",
    "DT =  AdaBoostClassifier(random_state=52,n_estimators= 1500, learning_rate= 0.01)\n",
    "scores = cross_validate(DT, X_train_sel, y_train, scoring=scoring, cv=k)\n",
    "DT.fit(X_train_sel,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63caa1bc-5b0a-4848-9fd9-db8b7d8553d0",
     "showTitle": true,
     "title": "PR_AUC curve"
    }
   },
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "pred_prob1 = GB.predict_proba(X_test_sel)\n",
    "pred_prob2 = RF.predict_proba(X_test_sel)\n",
    "#pred_prob3 = XB.predict_proba(X_test_sel)\n",
    "pred_prob4 = LR.predict_proba(X_test_sel1)\n",
    "pred_prob6 = DT.predict_proba(X_test_sel)\n",
    "\n",
    "precision1, recall1, _  = precision_recall_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
    "precision2, recall2, _  = precision_recall_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
    "#precision3, recall3, _  = precision_recall_curve(y_test, pred_prob3[:,1], pos_label=1)\n",
    "precision4, recall4, _  = precision_recall_curve(y_test, pred_prob4[:,1], pos_label=1)\n",
    "precision6, recall6, _  = precision_recall_curve(y_test, pred_prob6[:,1], pos_label=1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.plot(recall1,precision1, linestyle='--',dashes=(5, 1),color='orange', label='Gradient Boosting')\n",
    "plt.plot(recall2,precision2, linestyle='--', dashes=(5, 2),color='green', label='Random Forest')\n",
    "#plt.plot(recall3,precision3, linestyle='--', dashes=(5, 3), color='red', label='Extreme Gradient Boosting')\n",
    "plt.plot(recall4,precision4, linestyle='--', dashes=(5, 4),color='blue', label='Logistic Regression')\n",
    "plt.plot(recall6,precision6, linestyle='--', dashes=(5, 5),color='brown', label='Adaptive Boosting')\n",
    "plt.plot([0, 1], [0, 0], color='black', linestyle='--')\n",
    "\n",
    "plt.title('Precision_Recall Curve', fontsize=16)\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.xlabel(\"True Positive Rate (Recall)\", fontsize=16)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.ylabel(\"Positive Predictive Value (Precision)\", fontsize=16)\n",
    "plt.grid(False)\n",
    "#plt.legend(ncol=1,loc='center left',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd662ae4-8453-49ef-8a71-d7ea99d6e908",
     "showTitle": true,
     "title": "ROC Curve"
    }
   },
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "pred_prob1 = GB.predict_proba(X_test_sel)\n",
    "pred_prob2 = RF.predict_proba(X_test_sel)\n",
    "#pred_prob3 = XB.predict_proba(X_test_sel)\n",
    "pred_prob4 = LR.predict_proba(X_test_sel1)\n",
    "pred_prob6 = DT.predict_proba(X_test_sel)\n",
    "\n",
    "fpr1, tpr1, _  = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
    "fpr2, tpr2, _  = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
    "#fpr3, tpr3, _  = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\n",
    "fpr4, tpr4, _  = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n",
    "fpr6, tpr6, _  = roc_curve(y_test, pred_prob6[:,1], pos_label=1)\n",
    "\n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.plot(fpr1, tpr1, linestyle='-',dashes=(5, 1),color='orange', label='Gradient Boosting')\n",
    "plt.plot(fpr2, tpr2, linestyle='-',dashes=(5, 2),color='green', label='Random Forest')\n",
    "#plt.plot(fpr3, tpr3, linestyle='-',dashes=(5, 3),color='red', label='Extreme Gradient Boosting')\n",
    "plt.plot(fpr4, tpr4, linestyle='-',dashes=(5, 4),color='blue', label='Logistic Regression')\n",
    "plt.plot(fpr6, tpr6, linestyle='-',dashes=(5, 5),color='brown', label='Adaptive Boosting')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--',color='black')\n",
    "\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.ylabel(\"True Positive rate (Recall)\", fontsize=16)\n",
    "plt.grid(False)\n",
    "plt.legend(ncol=1,loc='lower right',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3daa7da7-9f38-447e-8f06-bc866eb88a74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "means_full = [0.764732,0.821687,0.802738,0.821249,0.785542]\n",
    "ci_full = [(0.65, 0.85), (0.71, 0.93), (0.69, 0.91),(0.71, 0.93),(0.67, 0.90)]\n",
    "y_r_full = [means_full[i] - ci_full[i][1] for i in range(len(ci_full))]\n",
    "\n",
    "\n",
    "means_prag = [0.720701,0.745126,0.740526,0.736254,0.727273]\n",
    "ci_prag = [(0.60, 0.84), (0.62, 0.87), (0.62, 0.86),(0.61, 0.86),(0.60, 0.85)]\n",
    "y_r_prag = [means_prag[i] - ci_prag[i][1] for i in range(len(ci_prag))]\n",
    "######################################################################################\n",
    "colors = ['violet', 'seagreen', 'crimson', 'blue', 'orange']\n",
    "\n",
    "ind = np.arange(len(means_full))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(8)\n",
    "fig.patch.set_facecolor('w')\n",
    "fig.patch.set_alpha(0.2)\n",
    "ax.patch.set_facecolor('w')\n",
    "ax.patch.set_alpha(0.1)\n",
    "ax.set_ylim(0,1.19)\n",
    "\n",
    "rects1 = ax.bar(ind - width/2, means_full, width, yerr=y_r_full,\n",
    "                label='Full Model',color='firebrick',zorder=3)\n",
    "rects2 = ax.bar(ind + width/2, means_prag, width, yerr=y_r_prag,color='indianred',\n",
    "                label='Medical Pragmatic Model',zorder=3)\n",
    "\n",
    "ax.set_xticks(np.arange(5))\n",
    "ax.grid(zorder=0)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('AUROC values and Error Bars', fontsize=14)\n",
    "ax.set_xlabel('Algorithm', fontsize=14)\n",
    "ax.set_title('Test Set AUROC', fontsize=16)\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(('LR', 'RF', 'GBDT', 'XGBT', 'AdaBoost'))\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "#ax.legend(handles=[rects1, rects2], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19052726-dcec-4a34-8fc4-4510d5f566cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "means_full = [0.400642,0.431107,0.432517,0.433493,0.373087]\n",
    "ci_full = [(0.20, 0.61), (0.22, 0.64), (0.23, 0.64),(0.23, 0.64),(0.17, 0.58)]\n",
    "y_r_full = [means_full[i] - ci_full[i][1] for i in range(len(ci_full))]\n",
    "\n",
    "\n",
    "means_prag = [0.397938,0.371921,0.399594,0.404474,0.369759]\n",
    "ci_prag = [(0.19, 0.60), (0.17, 0.57), (0.20, 0.60),(0.20, 0.61),(0.17, 0.57)]\n",
    "y_r_prag = [means_prag[i] - ci_prag[i][1] for i in range(len(ci_prag))]\n",
    "######################################################################################\n",
    "colors = ['violet', 'seagreen', 'crimson', 'blue', 'orange']\n",
    "\n",
    "ind = np.arange(len(means_full))  # the x locations for the groups\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(8)\n",
    "fig.patch.set_facecolor('w')\n",
    "fig.patch.set_alpha(0.2)\n",
    "ax.patch.set_facecolor('w')\n",
    "ax.patch.set_alpha(0.1)\n",
    "ax.set_ylim(0,1)\n",
    "\n",
    "rects1 = ax.bar(ind - width/2, means_full, width, yerr=y_r_full,\n",
    "                label='Full Model',color='mediumblue',zorder=3)\n",
    "rects2 = ax.bar(ind + width/2, means_prag, width, yerr=y_r_prag,color='mediumturquoise',hatch='',\n",
    "                label='Medical Pragmatic Model',zorder=3)\n",
    "\n",
    "ax.set_xticks(np.arange(5))\n",
    "ax.grid(zorder=0)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel(' PR-AUC values and Error Bars', fontsize=14)\n",
    "ax.set_xlabel('Algorithm', fontsize=14)\n",
    "ax.set_title('Test Set PR-AUC', fontsize=16)\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(('LR', 'RF', 'GBDT', 'XGBT', 'AdaBoost'))\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "#ax.legend(handles=[rects1, rects2], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5659f6c6-4c3e-4fe7-a783-bd172e7fd422",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Comparing the performance of two models on one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d82643a6-e547-4861-b1c7-815c880b11ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk = np.random.rand(len(pdf)) <= 0.8\n",
    "train = pdf[msk]\n",
    "test = pdf[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db81aaae-d263-45c7-8423-e96e09311912",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_gen = train\n",
    "test_gen = test\n",
    "train_old = train[train[\"age\"] >= 50]\n",
    "test_old = test[test[\"age\"] >= 50]\n",
    "train_young = train[train[\"age\"] < 50]\n",
    "test_young = test[test[\"age\"] < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08b71539-cb89-4270-a5b7-00941a714e07",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Categorical_chosen_features = ['Race','Sex','Ethnicity','Hypertension', 'Asthma', 'COPD', 'Malignancy', 'Liver disease', 'Chronic kidney disease', 'Hyperlipidemia', 'Obstructive sleep apnea', 'Diabetes', 'Solid organ transplant','Immunosuppression','Dementia','Alzheimer','Coronary arteriosclerosis','Heart failure','Cardiomyopathy']\n",
    "###############################################################################################################\n",
    "numerical_chosen_features = ['WHO ordinal score', 'BMI','Age',\n",
    "                             'HR (Maximum)','HR (Mean)','HR (Minimum)','HR (Standard deviation)',\n",
    "                             'SBP (Maximum)','SBP (Mean)','SBP (Minimum)', 'SBP (Standard deviation)',\n",
    "                             'DBP (Maximum)','DBP (Mean)', 'DBP (Minimum)', 'DBP (Standard deviation)',\n",
    "                             'Temperature (Maximum)', 'Temperature (Mean)', 'Temperature (Minimum)', 'Temperature (Standard deviation)',\n",
    "                             'RR (Maximum)','RR (Mean)', 'RR (Minimum)',  'RR (Standard deviation)',\n",
    "                             'SPO2 (Maximum)','SPO2 (Mean)', 'SPO2 (Min)', 'SPO2 (Standard deviation)',\n",
    "                  'WBC', 'LYMABS', 'HCT','HGB', 'NA', 'ALB', 'CA', 'K', 'CREA', 'GLU','ALT','AST', 'NEUABS','EOSABS','PLT'\n",
    "                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75ead999-f302-4ef5-8dd4-f9464341d85a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prep(df, label_name,features):\n",
    "  df = df.dropna(subset=[label_name])\n",
    "  y = df[label_name]\n",
    "  X = df[features]\n",
    "  \n",
    "  undersample = RandomUnderSampler(sampling_strategy='majority',random_state=52)\n",
    "  X_over, y_over = undersample.fit_resample(X, y)\n",
    "  \n",
    "  train_X = X_over\n",
    "  \n",
    "  train_y = y_over\n",
    "  \n",
    "  return train_X, train_y\n",
    "  \n",
    "###########################\n",
    "k=10\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_weighted', 'roc_auc', 'neg_mean_squared_error']\n",
    "#label_name = 'bi_severity_7'\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "ml = Pipeline([('preprocess', preprocessor),\n",
    "('classifier',RandomForestClassifier(class_weight=\"balanced\",random_state=52))])\n",
    "  \n",
    "ohe = (ml.named_steps['preprocess'])\n",
    "feature_names = np.r_[Categorical_chosen_features, numerical_chosen_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f380e3b2-575b-48a9-b8a1-a3e3ba0e7243",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91533b93-042b-4d5d-91fa-1caf75ee9bdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_X, train_y = prep(train_gen,label_name,feature_names)\n",
    "test_X = test[feature_names]\n",
    "test_y = test[label_name]\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(train_X)\n",
    "#################################################\n",
    "#################################################\n",
    "X_train_v1 = preprocessor.transform(train_X)\n",
    "X_test_v1 = preprocessor.transform(test_X)\n",
    "  \n",
    "train_v2 = pd.DataFrame(X_train_v1, columns=feature_names)\n",
    "test_v2 = pd.DataFrame(X_test_v1, columns=feature_names)\n",
    "\n",
    "#dataset=correlation(train_v2, 0.7)  ###\n",
    "#train_v2_sel = dataset ###\n",
    "#test_v2_sel = test_v2[dataset.columns] ###\n",
    "\n",
    "train_v3 = train_v2.drop(\"age\",axis=1)\n",
    "test_v3 = test_v2.drop(\"age\",axis=1)\n",
    "\n",
    "#dataset=correlation(train_v3, 0.7)\n",
    "#train_v3_sel = dataset\n",
    "#test_v3_sel = test_v3[dataset.columns]\n",
    "\n",
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [5,7,10],\n",
    "              'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "\n",
    "GB = GradientBoostingClassifier()\n",
    "GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"f1_micro\",cv=2, n_iter=100,random_state=52)\n",
    "GB_search.fit(train_v2, train_y)\n",
    "GB_search.best_params_\n",
    "############\n",
    "#GB = GradientBoostingClassifier()\n",
    "#GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"f1_micro\",cv=2, n_iter=100,random_state=52)\n",
    "#GB_search.fit(train_v3, train_y)\n",
    "#GB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a52ddf15-c5f0-4d2f-bf2f-f4a02311fd42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_X_old, train_y_old = prep(train_old,label_name,feature_names)\n",
    "test_X_old = test_old[feature_names]\n",
    "test_y_old = test_old[label_name]\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(train_X_old)\n",
    " \n",
    "X_train_old = preprocessor.transform(train_X_old)\n",
    "X_test_old = preprocessor.transform(test_X_old)\n",
    "  \n",
    "train_old_ad = pd.DataFrame(X_train_old, columns=feature_names)\n",
    "test_old_ad = pd.DataFrame(X_test_old, columns=feature_names)\n",
    "\n",
    "#dataset=correlation(train_old_ad, 0.7)  ###\n",
    "#train_old_sel = dataset ###\n",
    "#test_old_sel = test_old_ad[dataset.columns] ###\n",
    "\n",
    "train_old2=train_old_ad.drop(\"age\",axis=1)\n",
    "test_old2=test_old_ad.drop(\"age\",axis=1)\n",
    "\n",
    "#dataset=correlation(train_old2, 0.7)  ###\n",
    "#train_old2_sel = dataset ###\n",
    "#test_old2_sel = test_old2[dataset.columns] ###\n",
    "#################################################\n",
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [5,7,10],\n",
    "              'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "\n",
    "GB = GradientBoostingClassifier()\n",
    "GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"f1_micro\",cv=2, n_iter=100,random_state=52)\n",
    "GB_search.fit(train_old_ad, train_y_old)\n",
    "GB_search.best_params_\n",
    "############\n",
    "#GB = GradientBoostingClassifier()\n",
    "#GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"f1_micro\",cv=2, n_iter=100,random_state=52)\n",
    "#GB_search.fit(train_old2, train_y_old)\n",
    "#GB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd1baaca-0e24-4074-bba3-28ca06ee6640",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_X_young, train_y_young = prep(train_young,label_name,feature_names)\n",
    "test_X_young = test_young[feature_names]\n",
    "test_y_young = test_young[label_name]\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(train_X_young)\n",
    " \n",
    "X_train_young = preprocessor.transform(train_X_young)\n",
    "X_test_young = preprocessor.transform(test_X_young)\n",
    "\n",
    "train_young_ad = pd.DataFrame(X_train_young, columns=feature_names)\n",
    "test_young_ad = pd.DataFrame(X_test_young, columns=feature_names)\n",
    "\n",
    "#dataset=correlation(train_young_ad, 0.7)  ###\n",
    "#train_young_sel = dataset ###\n",
    "#test_young_sel = test_young_ad[dataset.columns] ###\n",
    "\n",
    "train_young2=train_young_ad.drop(\"age\",axis=1)\n",
    "test_young2=test_young_ad.drop(\"age\",axis=1)\n",
    "\n",
    "#dataset=correlation(train_young2, 0.7)  ###\n",
    "#train_young2_sel = dataset ###\n",
    "#test_young2_sel = test_young2[dataset.columns] \n",
    "#################################################\n",
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [5,7,10],\n",
    "              'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "\n",
    "GB = GradientBoostingClassifier()\n",
    "GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"f1_micro\",cv=2, n_iter=100,random_state=52)\n",
    "GB_search.fit(train_young_ad, train_y_young)\n",
    "GB_search.best_params_\n",
    "############\n",
    "#GB = GradientBoostingClassifier()\n",
    "#GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"f1_micro\",cv=2, n_iter=100,random_state=52)\n",
    "#GB_search.fit(train_young2, train_y_young)\n",
    "#GB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "850e2775-25b2-47ff-be09-f3d9ff228eab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "GBAll=GradientBoostingClassifier(random_state=52) \n",
    "scores = cross_validate(GBAll, train_v2, train_y, scoring=scoring, cv=k)\n",
    "GBAll.fit(train_v2,train_y)\n",
    "pred = GBAll.predict_proba(test_v2)\n",
    "pred_res = GBAll.predict(test_v2)\n",
    "roc_auc = compute_auc(pred, test_y)\n",
    "print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y)[0]\n",
    "FP = compute_performance(pred_res, test_y)[1]\n",
    "TN = compute_performance(pred_res, test_y)[2]\n",
    "FN = compute_performance(pred_res, test_y)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc / (2 - roc_auc)\n",
    "Q2 = 2*roc_auc**2 / (1 + roc_auc)\n",
    "SE_AUC = sqrt((roc_auc*(1 - roc_auc) + (N1 - 1)*(Q1 - roc_auc**2) + (N2 - 1)*(Q2 - roc_auc**2)) / (N1*N2))\n",
    "print(1.96*SE_AUC)\n",
    "#########################################################################\n",
    "GBAll_noage=GradientBoostingClassifier(random_state=52)\n",
    "scores = cross_validate(GBAll_noage, train_v3, train_y, scoring=scoring, cv=k)\n",
    "GBAll_noage.fit(train_v3,train_y)\n",
    "pred = GBAll_noage.predict_proba(test_v3)\n",
    "pred_res = GBAll_noage.predict(test_v3)\n",
    "roc_auc = compute_auc(pred, test_y)\n",
    "print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y)[0]\n",
    "FP = compute_performance(pred_res, test_y)[1]\n",
    "TN = compute_performance(pred_res, test_y)[2]\n",
    "FN = compute_performance(pred_res, test_y)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc / (2 - roc_auc)\n",
    "Q2 = 2*roc_auc**2 / (1 + roc_auc)\n",
    "SE_AUC = sqrt((roc_auc*(1 - roc_auc) + (N1 - 1)*(Q1 - roc_auc**2) + (N2 - 1)*(Q2 - roc_auc**2)) / (N1*N2))\n",
    "print(1.96*SE_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8ac41de-4b7f-4300-9bee-6a52791fafaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_sel = train_v2.columns\n",
    "X_test_v3 = test_v2[columns_sel]\n",
    "\n",
    "def model_predict(data_asarray):\n",
    "  data_asframe =  pd.DataFrame(data_asarray, columns= columns_sel)\n",
    "  return GBAll.predict(data_asframe)\n",
    "\n",
    "shap_values_Tree = shap.TreeExplainer(GBAll).shap_values(X_test_v3)\n",
    "\n",
    "shap.initjs()\n",
    "shap.dependence_plot('age', shap_values_Tree, X_test_v3, interaction_index=None,dot_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a662e11f-6636-48bc-bca0-74d7e36347a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "GBOld=GradientBoostingClassifier(random_state=52) \n",
    "scores = cross_validate(GBOld, train_old_ad,train_y_old, scoring=scoring, cv=k)\n",
    "GBOld.fit(train_old_ad,train_y_old)\n",
    "\n",
    "GBOld2=GradientBoostingClassifier(random_state=52) \n",
    "scores = cross_validate(GBOld2, train_old2,train_y_old, scoring=scoring, cv=k)\n",
    "GBOld2.fit(train_old2,train_y_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed617e20-a4af-42e5-b2bb-a089e00fe616",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_sel = train_old_ad.columns\n",
    "X_test_v3 = test_old_ad[columns_sel]\n",
    "\n",
    "def model_predict(data_asarray):\n",
    "  data_asframe =  pd.DataFrame(data_asarray, columns= columns_sel)\n",
    "  return GBOld.predict(data_asframe)\n",
    "\n",
    "shap_values_Tree = shap.TreeExplainer(GBOld).shap_values(X_test_v3)\n",
    "\n",
    "shap.initjs()\n",
    "shap.dependence_plot('age', shap_values_Tree, X_test_v3, interaction_index=None,dot_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07b1828d-8a4e-4b97-b5f2-d227a463e39b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "GByoung=GradientBoostingClassifier(random_state=52) \n",
    "scores = cross_validate(GByoung, train_young_ad,train_y_young, scoring=scoring, cv=k)\n",
    "GByoung.fit(train_young_ad,train_y_young)\n",
    "\n",
    "GByoung2=GradientBoostingClassifier(random_state=52)  \n",
    "scores = cross_validate(GByoung2, train_young2,train_y_young, scoring=scoring, cv=k)\n",
    "GByoung2.fit(train_young2,train_y_young)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e612b4a7-4f63-47cf-8786-f7efd3f662cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_sel = train_young_ad.columns\n",
    "X_test_v3 = test_young_ad[columns_sel]\n",
    "\n",
    "def model_predict(data_asarray):\n",
    "  data_asframe =  pd.DataFrame(data_asarray, columns= columns_sel)\n",
    "  return GByoung.predict(data_asframe)\n",
    "\n",
    "shap_values_Tree = shap.TreeExplainer(GByoung).shap_values(X_test_v3)\n",
    "\n",
    "shap.initjs()\n",
    "shap.dependence_plot('age', shap_values_Tree, X_test_v3, interaction_index=None,dot_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0d1ae2a-b7fa-4210-a3e1-74deb4ce4d19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# predict probabilities\n",
    "pred_prob1 = GBAll.predict_proba(test_v2)\n",
    "pred_res = GBAll.predict(test_v2)\n",
    "fpr1, tpr1, _  = roc_curve(test_y, pred_prob1[:,1], pos_label=1)\n",
    "roc_auc_All=metrics.auc(fpr1, tpr1)\n",
    "#print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y)[0]\n",
    "FP = compute_performance(pred_res, test_y)[1]\n",
    "TN = compute_performance(pred_res, test_y)[2]\n",
    "FN = compute_performance(pred_res, test_y)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc_All / (2 - roc_auc_All)\n",
    "Q2 = 2*roc_auc_All**2 / (1 + roc_auc_All)\n",
    "SE_AUC_All = sqrt((roc_auc_All*(1 - roc_auc_All) + (N1 - 1)*(Q1 - roc_auc_All**2) + (N2 - 1)*(Q2 - roc_auc_All**2)) / (N1*N2))\n",
    "SE_All = (1.96*SE_AUC_All)\n",
    "\n",
    "pred_prob2 = GBAll_noage.predict_proba(test_v3)\n",
    "pred_res = GBAll_noage.predict(test_v3)\n",
    "fpr2, tpr2, _  = roc_curve(test_y, pred_prob2[:,1], pos_label=1)\n",
    "roc_auc_Old1=metrics.auc(fpr2, tpr2)\n",
    "#print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y)[0]\n",
    "FP = compute_performance(pred_res, test_y)[1]\n",
    "TN = compute_performance(pred_res, test_y)[2]\n",
    "FN = compute_performance(pred_res, test_y)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc_Old1 / (2 - roc_auc_Old1)\n",
    "Q2 = 2*roc_auc_Old1**2 / (1 + roc_auc_Old1)\n",
    "SE_AUC_Old1 = sqrt((roc_auc_Old1*(1 - roc_auc_Old1) + (N1 - 1)*(Q1 - roc_auc_Old1**2) + (N2 - 1)*(Q2 - roc_auc_Old1**2)) / (N1*N2))\n",
    "SE_Old1=1.96*SE_AUC_Old1\n",
    "\n",
    "random_probs = [0 for i in range(len(test_y))]\n",
    "p_fpr, p_tpr, _ = roc_curve(test_y, random_probs, pos_label=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.plot(fpr1, tpr1, linestyle='-',dashes=(5, 1),color='orange', label='Generalized model\\n(Age is included),\\nAUC: (%.03f±%.03f)' %(roc_auc_All, SE_All))\n",
    "plt.plot(fpr2, tpr2, linestyle='-',dashes=(5, 3),color='green', label='Generalized model\\n(Age is not included),\\nAUC: (%.03f±%.03f)' %(roc_auc_Old1, SE_Old1))\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--',color='black')\n",
    "\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.ylabel(\"True Positive rate\", fontsize=16)\n",
    "\n",
    "plt.legend(loc='lower right',fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a6872cf-d397-4ec5-a2e1-5aeb8b4ff9af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# predict probabilities\n",
    "pred_prob1 = GBAll.predict_proba(test_old_ad)\n",
    "pred_res = GBAll.predict(test_old_ad)\n",
    "fpr1, tpr1, _  = roc_curve(test_y_old, pred_prob1[:,1], pos_label=1)\n",
    "roc_auc_All=metrics.auc(fpr1, tpr1)\n",
    "#print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y_old)[0]\n",
    "FP = compute_performance(pred_res, test_y_old)[1]\n",
    "TN = compute_performance(pred_res, test_y_old)[2]\n",
    "FN = compute_performance(pred_res, test_y_old)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc_All / (2 - roc_auc_All)\n",
    "Q2 = 2*roc_auc_All**2 / (1 + roc_auc_All)\n",
    "SE_AUC_All = sqrt((roc_auc_All*(1 - roc_auc_All) + (N1 - 1)*(Q1 - roc_auc_All**2) + (N2 - 1)*(Q2 - roc_auc_All**2)) / (N1*N2))\n",
    "SE_All = (1.96*SE_AUC_All)\n",
    "\n",
    "pred_prob2 = GBOld.predict_proba(test_old_ad)\n",
    "pred_res = GBOld.predict(test_old_ad)\n",
    "fpr2, tpr2, _  = roc_curve(test_y_old, pred_prob2[:,1], pos_label=1)\n",
    "roc_auc_Old1=metrics.auc(fpr2, tpr2)\n",
    "#print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y_old)[0]\n",
    "FP = compute_performance(pred_res, test_y_old)[1]\n",
    "TN = compute_performance(pred_res, test_y_old)[2]\n",
    "FN = compute_performance(pred_res, test_y_old)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc_Old1 / (2 - roc_auc_Old1)\n",
    "Q2 = 2*roc_auc_Old1**2 / (1 + roc_auc_Old1)\n",
    "SE_AUC_Old1 = sqrt((roc_auc_Old1*(1 - roc_auc_Old1) + (N1 - 1)*(Q1 - roc_auc_Old1**2) + (N2 - 1)*(Q2 - roc_auc_Old1**2)) / (N1*N2))\n",
    "SE_Old1=1.96*SE_AUC_Old1\n",
    "\n",
    "pred_prob3 = GBOld2.predict_proba(test_old2)\n",
    "pred_res = GBOld2.predict(test_old2)\n",
    "fpr3, tpr3, _  = roc_curve(test_y_old, pred_prob3[:,1], pos_label=1)\n",
    "roc_auc_Old2=metrics.auc(fpr3, tpr3)\n",
    "#print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y_old)[0]\n",
    "FP = compute_performance(pred_res, test_y_old)[1]\n",
    "TN = compute_performance(pred_res, test_y_old)[2]\n",
    "FN = compute_performance(pred_res, test_y_old)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc_Old2 / (2 - roc_auc_Old2)\n",
    "Q2 = 2*roc_auc_Old2**2 / (1 + roc_auc_Old2)\n",
    "SE_AUC_Old2 = sqrt((roc_auc_Old2*(1 - roc_auc_Old2) + (N1 - 1)*(Q1 - roc_auc_Old2**2) + (N2 - 1)*(Q2 - roc_auc_Old2**2)) / (N1*N2))\n",
    "SE_Old2=1.96*SE_AUC_Old2\n",
    "\n",
    "random_probs = [0 for i in range(len(test_y))]\n",
    "p_fpr, p_tpr, _ = roc_curve(test_y, random_probs, pos_label=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.plot(fpr1, tpr1, linestyle='-',dashes=(5, 1),color='orange', label='Generalized model\\n(Age is included),\\nAUC: (%.02f±%.02f)' %(roc_auc_All, SE_All))\n",
    "plt.plot(fpr2, tpr2, linestyle='-',dashes=(5, 3),color='green', label='Age-specific model\\n(Age is included),\\nAUC: (%.02f±%.02f)' %(roc_auc_Old1, SE_Old1))\n",
    "plt.plot(fpr3, tpr3, linestyle='-',dashes=(5, 5),color='blue', label='Age-specific model\\n(Age is not included),\\nAUC: (%.02f±%.02f)' %(roc_auc_Old2, SE_Old2))\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--',color='black')\n",
    "\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.ylabel(\"True Positive rate\", fontsize=16)\n",
    "\n",
    "plt.legend(loc='lower right',fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6427410-9362-48b7-9884-356d9ab01351",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# predict probabilities\n",
    "pred_prob1 = GBAll.predict_proba(test_young_ad)\n",
    "pred_res = GBAll.predict(test_young_ad)\n",
    "fpr1, tpr1, _  = roc_curve(test_y_young, pred_prob1[:,1], pos_label=1)\n",
    "roc_auc_All=metrics.auc(fpr1, tpr1)\n",
    "#print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y_young)[0]\n",
    "FP = compute_performance(pred_res, test_y_young)[1]\n",
    "TN = compute_performance(pred_res, test_y_young)[2]\n",
    "FN = compute_performance(pred_res, test_y_young)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc_All / (2 - roc_auc_All)\n",
    "Q2 = 2*roc_auc_All**2 / (1 + roc_auc_All)\n",
    "SE_AUC_All = sqrt((roc_auc_All*(1 - roc_auc_All) + (N1 - 1)*(Q1 - roc_auc_All**2) + (N2 - 1)*(Q2 - roc_auc_All**2)) / (N1*N2))\n",
    "SE_All=1.96*SE_AUC_All\n",
    "\n",
    "pred_prob2 = GByoung.predict_proba(test_young_ad)\n",
    "pred_res = GByoung.predict(test_young_ad)\n",
    "fpr2, tpr2, _  = roc_curve(test_y_young, pred_prob2[:,1], pos_label=1)\n",
    "roc_auc_young1=metrics.auc(fpr2, tpr2)\n",
    "#print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y_young)[0]\n",
    "FP = compute_performance(pred_res, test_y_young)[1]\n",
    "TN = compute_performance(pred_res, test_y_young)[2]\n",
    "FN = compute_performance(pred_res, test_y_young)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc_young1 / (2 - roc_auc_young1)\n",
    "Q2 = 2*roc_auc_young1**2 / (1 + roc_auc_young1)\n",
    "SE_AUC_young1 = sqrt((roc_auc_young1*(1 - roc_auc_young1) + (N1 - 1)*(Q1 - roc_auc_young1**2) + (N2 - 1)*(Q2 - roc_auc_young1**2)) / (N1*N2))\n",
    "SE_young1=1.96*SE_AUC_young1\n",
    "\n",
    "pred_prob3 = GByoung2.predict_proba(test_young2)\n",
    "pred_res = GByoung2.predict(test_young2)\n",
    "fpr3, tpr3, _  = roc_curve(test_y_young, pred_prob3[:,1], pos_label=1)\n",
    "roc_auc_young2=metrics.auc(fpr3, tpr3)\n",
    "#print(roc_auc)\n",
    "TP = compute_performance(pred_res, test_y_young)[0]\n",
    "FP = compute_performance(pred_res, test_y_young)[1]\n",
    "TN = compute_performance(pred_res, test_y_young)[2]\n",
    "FN = compute_performance(pred_res, test_y_young)[3]\n",
    "N1 = TP+FN\n",
    "N2 = FP+TN\n",
    "Q1 = roc_auc_young2 / (2 - roc_auc_young2)\n",
    "Q2 = 2*roc_auc_young2**2 / (1 + roc_auc_young2)\n",
    "SE_AUC_young2 = sqrt((roc_auc_young2*(1 - roc_auc_young2) + (N1 - 1)*(Q1 - roc_auc_young2**2) + (N2 - 1)*(Q2 - roc_auc_young2**2)) / (N1*N2))\n",
    "SE_young2=1.96*SE_AUC_young2\n",
    "\n",
    "random_probs = [0 for i in range(len(test_y))]\n",
    "p_fpr, p_tpr, _ = roc_curve(test_y, random_probs, pos_label=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.plot(fpr1, tpr1, linestyle='-',dashes=(5, 1),color='orange', label='Generalized model\\n(Age is included),\\nAUC: (%.03f±%.03f)' %(roc_auc_All, SE_All))\n",
    "plt.plot(fpr2, tpr2, linestyle='-',dashes=(5, 3),color='green', label='Age-specific model\\n(Age is included),\\nAUC: (%.03f±%.03f)' %(roc_auc_young1, SE_young1))\n",
    "plt.plot(fpr3, tpr3, linestyle='-',dashes=(5, 5),color='blue', label='Age-specific model\\n(Age is not included),\\nAUC: (%.03f±%.03f)' %(roc_auc_young2, SE_young2))\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--',color='black')\n",
    "\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.ylabel(\"True Positive rate\", fontsize=16)\n",
    "\n",
    "plt.legend(loc='lower right',fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3981a81-b0d5-4e49-b219-1628795e0dae",
     "showTitle": true,
     "title": "Different time intervals"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "np.random.seed(52)\n",
    "msk = np.random.rand(len(pdf)) <= 0.8\n",
    "train = pdf[msk]\n",
    "test = pdf[~msk]\n",
    "\n",
    "train_X1, train_y1 = data_prep_ML(train,'bi_severity_1',feature_names)\n",
    "train_X7, train_y7 = prep(train,'bi_severity_7',feature_names)\n",
    "train_X14, train_y14 = prep(train,'bi_severity_14',feature_names)\n",
    "train_X28, train_y28 = prep(train,'bi_severity_28',feature_names)\n",
    "train_X56, train_y56 = prep(train,'bi_severity_56',feature_names)\n",
    "\n",
    "test_X1 = test[feature_names]\n",
    "test_y1 = test['bi_severity_1']#\n",
    "test_X7 = test[feature_names]\n",
    "test_y7 = test['bi_severity_7']#\n",
    "test_X14 = test[feature_names]\n",
    "test_y14 = test['bi_severity_14']#\n",
    "test_X28 = test[feature_names]\n",
    "test_y28 = test['bi_severity_28']#\n",
    "test_X56 = test[feature_names]\n",
    "test_y56 = test['bi_severity_56']\n",
    "########################################\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(train_X1) \n",
    "X_train1_v1 = preprocessor.transform(train_X1)\n",
    "X_test1_v1 = preprocessor.transform(test_X1)\n",
    "train1_v2 = pd.DataFrame(X_train1_v1, columns=feature_names)\n",
    "test1_v2 = pd.DataFrame(X_test1_v1, columns=feature_names)\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(train_X7) \n",
    "X_train7_v1 = preprocessor.transform(train_X7)\n",
    "X_test7_v1 = preprocessor.transform(test_X7)\n",
    "train7_v2 = pd.DataFrame(X_train7_v1, columns=feature_names)\n",
    "test7_v2 = pd.DataFrame(X_test7_v1, columns=feature_names)\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(train_X14) \n",
    "X_train14_v1 = preprocessor.transform(train_X14)\n",
    "X_test14_v1 = preprocessor.transform(test_X14)\n",
    "train14_v2 = pd.DataFrame(X_train14_v1, columns=feature_names)\n",
    "test14_v2 = pd.DataFrame(X_test14_v1, columns=feature_names)\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(train_X28) \n",
    "X_train28_v1 = preprocessor.transform(train_X28)\n",
    "X_test28_v1 = preprocessor.transform(test_X28)\n",
    "train28_v2 = pd.DataFrame(X_train28_v1, columns=feature_names)\n",
    "test28_v2 = pd.DataFrame(X_test28_v1, columns=feature_names)\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_pipe, Categorical_chosen_features),('num', numerical_pipe, numerical_chosen_features)])\n",
    "preprocessor.fit(train_X56) \n",
    "X_train56_v1 = preprocessor.transform(train_X56)\n",
    "X_test56_v1 = preprocessor.transform(test_X56)\n",
    "train56_v2 = pd.DataFrame(X_train56_v1, columns=feature_names)\n",
    "test56_v2 = pd.DataFrame(X_test56_v1, columns=feature_names)\n",
    "####################\n",
    "GB1 = GradientBoostingClassifier(random_state=52,learning_rate=0.001,max_depth=5,n_estimators=1000,min_samples_split=10,min_samples_leaf= 8,max_features= 'log2')\n",
    "GB1.fit(train1_v2,train_y1)\n",
    "\n",
    "GB7=GradientBoostingClassifier(random_state=52)\n",
    "GB7.fit(train7_v2,train_y7)\n",
    "\n",
    "GB14=GradientBoostingClassifier(random_state=52,learning_rate=0.01,max_depth=5,n_estimators=1000,min_samples_split=2,min_samples_leaf= 6,max_features= 'log2')\n",
    "GB14.fit(train14_v2,train_y14)\n",
    "\n",
    "GB28=GradientBoostingClassifier(random_state=52,learning_rate=0.01,max_depth=5,n_estimators=1000,min_samples_split=4,min_samples_leaf= 1,max_features= 'log2')\n",
    "GB28.fit(train28_v2,train_y28)\n",
    "\n",
    "GB56=GradientBoostingClassifier(random_state=52,learning_rate=0.01,max_depth=10,n_estimators=1000,min_samples_split=2,min_samples_leaf= 2,max_features= 'sqrt')\n",
    "GB56.fit(train56_v2,train_y56)\n",
    "\n",
    "pred_prob1 = GB1.predict_proba(test1_v2)\n",
    "pred_prob7 = GB7.predict_proba(test7_v2)\n",
    "pred_prob14 = GB14.predict_proba(test14_v2)\n",
    "pred_prob28 = GB28.predict_proba(test28_v2)\n",
    "pred_prob56 = GB56.predict_proba(test56_v2)\n",
    "\n",
    "fpr1, tpr1, _  = roc_curve(test_y1, pred_prob1[:,1], pos_label=1)\n",
    "roc_auc1=metrics.auc(fpr1, tpr1)\n",
    "\n",
    "fpr7, tpr7, _  = roc_curve(test_y7, pred_prob7[:,1], pos_label=1)\n",
    "roc_auc7=metrics.auc(fpr7, tpr7)\n",
    "\n",
    "fpr14, tpr14, _  = roc_curve(test_y14, pred_prob14[:,1], pos_label=1)\n",
    "roc_auc14=metrics.auc(fpr14, tpr14)\n",
    "\n",
    "fpr28, tpr28, _  = roc_curve(test_y28, pred_prob28[:,1], pos_label=1)\n",
    "roc_auc28=metrics.auc(fpr28, tpr28)\n",
    "\n",
    "fpr56, tpr56, _  = roc_curve(test_y56, pred_prob56[:,1], pos_label=1)\n",
    "roc_auc56=metrics.auc(fpr56, tpr56)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.plot(fpr1, tpr1, linestyle='-',dashes=(5, 1),color='orange', label='1 day after admission, AUC: %.04f' %roc_auc1)\n",
    "plt.plot(fpr7, tpr7, linestyle='-',dashes=(5, 3),color='green', label='7 days after admission, AUC: %.04f' %roc_auc7)\n",
    "plt.plot(fpr14, tpr14, linestyle='-',dashes=(5, 5),color='blue', label='14 days after admission, AUC: %.04f' %roc_auc14)\n",
    "plt.plot(fpr28, tpr28, linestyle='-',color='red', label='28 days after admission, AUC: %.04f' %roc_auc28)\n",
    "plt.plot(fpr56, tpr56, linestyle='-',color='purple', label='56 days after admission, AUC: %.04f' %roc_auc56)\n",
    "#plt.plot(p_fpr, p_tpr, linestyle='--',color='black')\n",
    "\n",
    "plt.title('ROC curve', fontsize=16)\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1), fontsize=14)\n",
    "plt.ylabel(\"True Positive rate\", fontsize=16)\n",
    "\n",
    "plt.legend(loc='best',fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f3623cb-cb9c-4d8e-a4ea-0c959992e5fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [5,7,10],\n",
    "              'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "\n",
    "GB = GradientBoostingClassifier()\n",
    "GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"roc_auc\",cv=2, n_iter=100,random_state=52)\n",
    "GB_search.fit(train1_v2,train_y1)\n",
    "\n",
    "GB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc48b787-8169-4a58-9a11-c973be92a632",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [5,7,10],\n",
    "              'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "\n",
    "GB = GradientBoostingClassifier()\n",
    "GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"roc_auc\",cv=2, n_iter=100,random_state=52)\n",
    "GB_search.fit(train14_v2,train_y14)\n",
    "\n",
    "GB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bb89568-9fdb-453e-aaf1-9e95f21d3100",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [5,7,10],\n",
    "              'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "\n",
    "GB = GradientBoostingClassifier()\n",
    "GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"roc_auc\",cv=2, n_iter=100,random_state=52)\n",
    "GB_search.fit(train28_v2,train_y28)\n",
    "\n",
    "GB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fc6c067-e0ae-493d-a164-143e1ce982f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.01, 0.001],\n",
    "              'n_estimators': [1000],\n",
    "              'max_depth': [5,7,10],\n",
    "              'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "              'min_samples_split': [2, 4, 6, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2', None]}\n",
    "\n",
    "GB = GradientBoostingClassifier()\n",
    "GB_search = RandomizedSearchCV(estimator=GB,param_distributions=parameters,scoring = \"roc_auc\",cv=2, n_iter=100,random_state=52)\n",
    "GB_search.fit(train56_v2,train_y56)\n",
    "\n",
    "GB_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "554552ac-20ea-41c1-8297-220b61783359",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "PATT_model _All_Full",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
